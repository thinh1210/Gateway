{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a930151",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Divu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Divu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.2567, Accuracy: 89.23%\n",
      "Epoch 2/10, Loss: 0.0375, Accuracy: 98.87%\n",
      "Epoch 3/10, Loss: 0.0292, Accuracy: 99.00%\n",
      "Epoch 4/10, Loss: 0.0186, Accuracy: 99.49%\n",
      "Epoch 5/10, Loss: 0.0110, Accuracy: 99.62%\n",
      "Epoch 6/10, Loss: 0.0144, Accuracy: 99.59%\n",
      "Epoch 7/10, Loss: 0.0098, Accuracy: 99.74%\n",
      "Epoch 8/10, Loss: 0.0062, Accuracy: 99.92%\n",
      "Epoch 9/10, Loss: 0.0059, Accuracy: 99.90%\n",
      "Epoch 10/10, Loss: 0.0063, Accuracy: 99.90%\n",
      "‚úÖ M√¥ h√¨nh Siamese Network ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o 'siamese_face_recognition_model.pth'\n",
      "\n",
      "ƒê√°nh gi√° tr√™n t·∫≠p hu·∫•n luy·ªán:\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Different       1.00      1.00      1.00      1946\n",
      "        Same       1.00      1.00      1.00      1952\n",
      "\n",
      "    accuracy                           1.00      3898\n",
      "   macro avg       1.00      1.00      1.00      3898\n",
      "weighted avg       1.00      1.00      1.00      3898\n",
      "\n",
      "F1 Score: 1.0000, Precision: 1.0000, Recall: 1.0000\n",
      "\n",
      "Predicting images in folder: C:\\Users\\Divu\\Desktop\\DADN\\detect_face\\test_faces\n",
      "No images found in the folder. Please check the directory.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import os\n",
    "from PIL import Image\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report\n",
    "import time\n",
    "\n",
    "# ƒê·ªãnh nghƒ©a Siamese Network\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        # S·ª≠ d·ª•ng ResNet18 l√†m backbone, lo·∫°i b·ªè l·ªõp fully connected\n",
    "        self.backbone = models.resnet18(pretrained=False)\n",
    "        self.backbone.fc = nn.Identity()  # Lo·∫°i b·ªè l·ªõp fully connected\n",
    "        self.fc = nn.Linear(512, 128)  # Gi·∫£m chi·ªÅu vector ƒë·∫∑c tr∆∞ng xu·ªëng 128\n",
    "\n",
    "    def forward_one(self, x):\n",
    "        # X·ª≠ l√Ω m·ªôt nh√°nh c·ªßa Siamese Network\n",
    "        x = self.backbone(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        # X·ª≠ l√Ω hai h√¨nh ·∫£nh ƒë·∫ßu v√†o\n",
    "        output1 = self.forward_one(input1)\n",
    "        output2 = self.forward_one(input2)\n",
    "        return output1, output2\n",
    "\n",
    "# H√†m Contrastive Loss\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        # T√≠nh kho·∫£ng c√°ch Euclidean\n",
    "        euclidean_distance = torch.nn.functional.pairwise_distance(output1, output2)\n",
    "        # Loss cho c·∫∑p gi·ªëng nhau (label=1)\n",
    "        loss_same = label * torch.pow(euclidean_distance, 2)\n",
    "        # Loss cho c·∫∑p kh√°c nhau (label=0)\n",
    "        loss_diff = (1 - label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)\n",
    "        loss = torch.mean(loss_same + loss_diff) / 2\n",
    "        return loss, euclidean_distance\n",
    "\n",
    "# ƒê·ªãnh nghƒ©a dataset cho Siamese Network\n",
    "class SiameseFaceDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.label_to_idx = {}\n",
    "        \n",
    "        # Load t·∫•t c·∫£ ·∫£nh v√† nh√£n\n",
    "        folders = [f for f in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, f))]\n",
    "        for idx, folder in enumerate(sorted(folders)):\n",
    "            self.label_to_idx[folder] = idx\n",
    "            image_files = glob.glob(os.path.join(root_dir, folder, \"*.jpg\")) + \\\n",
    "                         glob.glob(os.path.join(root_dir, folder, \"*.png\"))\n",
    "            for img_path in image_files:\n",
    "                self.image_paths.append(img_path)\n",
    "                self.labels.append(idx)\n",
    "        \n",
    "        self.num_classes = len(self.label_to_idx)\n",
    "        self.label_to_images = {i: [] for i in range(self.num_classes)}\n",
    "        for img_path, label in zip(self.image_paths, self.labels):\n",
    "            self.label_to_images[label].append(img_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths) * 2  # TƒÉng s·ªë l∆∞·ª£ng m·∫´u ƒë·ªÉ t·∫°o c·∫∑p\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # L·∫•y ng·∫´u nhi√™n m·ªôt ·∫£nh\n",
    "        img1_idx = random.randint(0, len(self.image_paths) - 1)\n",
    "        img1_path = self.image_paths[img1_idx]\n",
    "        label1 = self.labels[img1_idx]\n",
    "        img1 = Image.open(img1_path).convert('RGB')\n",
    "\n",
    "        # Quy·∫øt ƒë·ªãnh ng·∫´u nhi√™n t·∫°o c·∫∑p gi·ªëng hay kh√°c\n",
    "        should_get_same_class = random.randint(0, 1)\n",
    "        if should_get_same_class:\n",
    "            # Ch·ªçn m·ªôt ·∫£nh kh√°c c√πng l·ªõp\n",
    "            same_class_images = self.label_to_images[label1]\n",
    "            img2_path = random.choice(same_class_images)\n",
    "            label = 1  # C√πng ng∆∞·ªùi\n",
    "        else:\n",
    "            # Ch·ªçn m·ªôt ·∫£nh t·ª´ l·ªõp kh√°c\n",
    "            different_class = random.choice([l for l in range(self.num_classes) if l != label1])\n",
    "            img2_path = random.choice(self.label_to_images[different_class])\n",
    "            label = 0  # Kh√°c ng∆∞·ªùi\n",
    "\n",
    "        img2 = Image.open(img2_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "\n",
    "        return img1, img2, torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "# H√†m hu·∫•n luy·ªán Siamese Network\n",
    "def train_siamese_model(model, dataloader, criterion, optimizer, num_epochs=5, device='cuda'):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for img1, img2, labels in dataloader:\n",
    "            img1, img2, labels = img1.to(device), img2.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output1, output2 = model(img1, img2)\n",
    "            loss, distances = criterion(output1, output2, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            # T√≠nh accuracy d·ª±a tr√™n ng∆∞·ª°ng kho·∫£ng c√°ch\n",
    "            predictions = (distances < 1.0).float()  # Ng∆∞·ª°ng 1.0 ƒë·ªÉ ph√¢n lo·∫°i\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(dataloader):.4f}, Accuracy: {accuracy:.2f}%')\n",
    "    \n",
    "    # L∆∞u m√¥ h√¨nh\n",
    "    torch.save(model.state_dict(), 'siamese_face_recognition_model.pth')\n",
    "    print(\"‚úÖ M√¥ h√¨nh Siamese Network ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o 'siamese_face_recognition_model.pth'\")\n",
    "\n",
    "# H√†m ƒë√°nh gi√° Siamese Network\n",
    "def evaluate_siamese_model(model, dataloader, device='cuda'):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for img1, img2, labels in dataloader:\n",
    "            img1, img2, labels = img1.to(device), img2.to(device), labels.to(device)\n",
    "            output1, output2 = model(img1, img2)\n",
    "            _, distances = ContrastiveLoss()(output1, output2, labels)\n",
    "            predictions = (distances < 1.0).float()  # Ng∆∞·ª°ng 1.0\n",
    "            all_preds.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # T√≠nh F1 score, precision, recall\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    # In b√°o c√°o chi ti·∫øt\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=['Different', 'Same']))\n",
    "    \n",
    "    return f1, precision, recall\n",
    "\n",
    "# H√†m d·ª± ƒëo√°n cho m·ªôt ·∫£nh\n",
    "def predict_siamese(model, image, reference_images, transform, label_to_idx, device='cuda', threshold=1.0):\n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "    idx_to_label = {v: k for k, v in label_to_idx.items()}\n",
    "    min_distance = float('inf')\n",
    "    predicted_label = \"Unknown\"\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "        feature1 = model.forward_one(image_tensor)\n",
    "        \n",
    "        for ref_img_path, ref_label in reference_images:\n",
    "            ref_img = Image.open(ref_img_path).convert('RGB')\n",
    "            ref_tensor = transform(ref_img).unsqueeze(0).to(device)\n",
    "            feature2 = model.forward_one(ref_tensor)\n",
    "            distance = torch.nn.functional.pairwise_distance(feature1, feature2).item()\n",
    "            \n",
    "            if distance < min_distance and distance < threshold:\n",
    "                min_distance = distance\n",
    "                predicted_label = idx_to_label[ref_label]\n",
    "    \n",
    "    end_time = time.time()\n",
    "    inference_time = end_time - start_time\n",
    "    return predicted_label, min_distance, inference_time\n",
    "\n",
    "# H√†m d·ª± ƒëo√°n cho to√†n b·ªô ·∫£nh trong m·ªôt th∆∞ m·ª•c\n",
    "def predict_siamese_folder(model, folder_path, reference_images, transform, label_to_idx, device='cuda', threshold=1.0):\n",
    "    print(f\"\\nPredicting images in folder: {folder_path}\")\n",
    "    \n",
    "    image_files = glob.glob(os.path.join(folder_path, \"*.jpg\")) + \\\n",
    "                  glob.glob(os.path.join(folder_path, \"*.png\"))\n",
    "    \n",
    "    if not image_files:\n",
    "        print(\"No images found in the folder. Please check the directory.\")\n",
    "        return\n",
    "    \n",
    "    results = []\n",
    "    total_inference_time = 0.0\n",
    "    prediction_counts = {}\n",
    "\n",
    "    for img_path in image_files:\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            result, distance, inference_time = predict_siamese(model, img, reference_images, transform, label_to_idx, device, threshold)\n",
    "            \n",
    "            print(f\"Image: {os.path.basename(img_path)}\")\n",
    "            print(f\"Prediction: {result} (Distance: {distance:.4f})\")\n",
    "            print(f\"Inference time: {inference_time:.6f} seconds\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            results.append((img_path, result, inference_time))\n",
    "            total_inference_time += inference_time\n",
    "            prediction_counts[result] = prediction_counts.get(result, 0) + 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {e}\")\n",
    "    \n",
    "    print(\"\\nSummary:\")\n",
    "    print(f\"Total images processed: {len(results)}\")\n",
    "    print(f\"Average inference time: {total_inference_time / len(results):.6f} seconds\")\n",
    "    print(\"\\nPrediction counts:\")\n",
    "    for label, count in prediction_counts.items():\n",
    "        print(f\"{label}: {count} images\")\n",
    "\n",
    "# Thi·∫øt l·∫≠p v√† hu·∫•n luy·ªán\n",
    "if __name__ == \"__main__\":\n",
    "    # Thi·∫øt l·∫≠p device\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    # Transform cho ·∫£nh\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # T·∫°o dataset v√† dataloader\n",
    "    dataset = SiameseFaceDataset(root_dir=r\"C:\\Users\\Divu\\Desktop\\DADN\\detect_face\\extracted_faces\", transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    # Kh·ªüi t·∫°o m√¥ h√¨nh v√† c√°c th√†nh ph·∫ßn\n",
    "    model = SiameseNetwork().to(device)\n",
    "    criterion = ContrastiveLoss(margin=2.0)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Hu·∫•n luy·ªán m√¥ h√¨nh\n",
    "    train_siamese_model(model, dataloader, criterion, optimizer, num_epochs=10, device=device)\n",
    "    \n",
    "    # ƒê√°nh gi√° m√¥ h√¨nh\n",
    "    print(\"\\nƒê√°nh gi√° tr√™n t·∫≠p hu·∫•n luy·ªán:\")\n",
    "    f1, precision, recall = evaluate_siamese_model(model, dataloader, device)\n",
    "    print(f\"F1 Score: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
    "    \n",
    "    # Chu·∫©n b·ªã ·∫£nh tham chi·∫øu (reference images) cho d·ª± ƒëo√°n\n",
    "    reference_images = []\n",
    "    for label, img_paths in dataset.label_to_images.items():\n",
    "        # Ch·ªçn m·ªôt ·∫£nh ƒë·∫°i di·ªán cho m·ªói nh√£n\n",
    "        reference_images.append((random.choice(img_paths), label))\n",
    "    \n",
    "    # D·ª± ƒëo√°n tr√™n th∆∞ m·ª•c test\n",
    "    test_folder = r\"C:\\Users\\Divu\\Desktop\\DADN\\detect_face\\test_faces\"\n",
    "    predict_siamese_folder(model, test_folder, reference_images, transform, dataset.label_to_idx, device, threshold=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2ed2bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå L·ªói khi t·∫£i m√¥ h√¨nh: [Errno 2] No such file or directory: 'siamese_face_recognition_simple_cnn.pth'\n",
      "Vui l√≤ng hu·∫•n luy·ªán l·∫°i m√¥ h√¨nh Siamese Network v·ªõi dataset hi·ªán t·∫°i.\n",
      "üöÄ B·∫Øt ƒë·∫ßu nh·∫≠n di·ªán khu√¥n m·∫∑t t·ª´ webcam...\n",
      "üõë Ng∆∞·ªùi d√πng ƒë√£ tho√°t\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "from datetime import datetime\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import glob\n",
    "import random\n",
    "\n",
    "# ƒê·ªãnh nghƒ©a backbone CNN ƒë∆°n gi·∫£n\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),  # Input: 3x224x224 -> Output: 32x224x224\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),       # Output: 32x112x112\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1), # Output: 64x112x112\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),       # Output: 64x56x56\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),# Output: 128x56x56\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)        # Output: 128x28x28\n",
    "        )\n",
    "        self.fc = nn.Linear(128 * 28 * 28, 128)  # Gi·∫£m chi·ªÅu v·ªÅ vector 128\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# ƒê·ªãnh nghƒ©a Siamese Network\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.backbone = SimpleCNN()\n",
    "\n",
    "    def forward_one(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.forward_one(input1)\n",
    "        output2 = self.forward_one(input2)\n",
    "        return output1, output2\n",
    "\n",
    "# H√†m d·ª± ƒëo√°n cho Siamese Network\n",
    "def predict(model, image, reference_images, transform, label_to_idx, device='cuda', threshold=1.0):\n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "    idx_to_label = {v: k for k, v in label_to_idx.items()}\n",
    "    min_distance = float('inf')\n",
    "    predicted_label = \"Unknown\"\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "        feature1 = model.forward_one(image_tensor)\n",
    "        \n",
    "        for ref_img_path, ref_label in reference_images:\n",
    "            ref_img = Image.open(ref_img_path).convert('RGB')\n",
    "            ref_tensor = transform(ref_img).unsqueeze(0).to(device)\n",
    "            feature2 = model.forward_one(ref_tensor)\n",
    "            distance = torch.nn.functional.pairwise_distance(feature1, feature2).item()\n",
    "            \n",
    "            if distance < min_distance and distance < threshold:\n",
    "                min_distance = distance\n",
    "                predicted_label = idx_to_label[ref_label]\n",
    "    \n",
    "    end_time = time.time()\n",
    "    inference_time = end_time - start_time\n",
    "    return predicted_label, inference_time\n",
    "\n",
    "class FaceRecognitionSystem:\n",
    "    def __init__(self, dataset_path=r\"C:\\Users\\Divu\\Desktop\\DADN\\detect_face\\extracted_faces\", detection_method=\"hog\", model_path=\"siamese_face_recognition_simple_cnn.pth\"):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.detection_method = detection_method\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "        # Transform cho ·∫£nh\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        # T·∫°o danh s√°ch nh√£n v√† ·∫£nh tham chi·∫øu\n",
    "        self.label_to_idx = {}\n",
    "        self.reference_images = []\n",
    "        folders = [f for f in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, f))]\n",
    "        for idx, folder in enumerate(sorted(folders)):\n",
    "            self.label_to_idx[folder] = idx\n",
    "            # Ch·ªçn m·ªôt ·∫£nh tham chi·∫øu ng·∫´u nhi√™n cho m·ªói nh√£n\n",
    "            image_files = glob.glob(os.path.join(dataset_path, folder, \"*.jpg\")) + \\\n",
    "                         glob.glob(os.path.join(dataset_path, folder, \"*.png\"))\n",
    "            if image_files:\n",
    "                self.reference_images.append((random.choice(image_files), idx))\n",
    "        \n",
    "        self.num_classes = len(self.label_to_idx)\n",
    "        \n",
    "        # Kh·ªüi t·∫°o m√¥ h√¨nh Siamese Network\n",
    "        self.model = SiameseNetwork().to(self.device)\n",
    "        \n",
    "        # T·∫£i tr·∫°ng th√°i m√¥ h√¨nh\n",
    "        try:\n",
    "            self.model.load_state_dict(torch.load(model_path, map_location=self.device))\n",
    "            self.model.eval()\n",
    "            print(f\"‚úÖ M√¥ h√¨nh Siamese Network ƒë√£ ƒë∆∞·ª£c t·∫£i t·ª´ {model_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå L·ªói khi t·∫£i m√¥ h√¨nh: {e}\")\n",
    "            print(\"Vui l√≤ng hu·∫•n luy·ªán l·∫°i m√¥ h√¨nh Siamese Network v·ªõi dataset hi·ªán t·∫°i.\")\n",
    "\n",
    "    def draw_rectangles(self, frame, top, right, bottom, left, label=\"Face\"):\n",
    "        padding = 0\n",
    "        top = max(0, top - padding)\n",
    "        left = max(0, left - padding)\n",
    "        right = min(frame.shape[1], right + padding)\n",
    "        bottom = min(frame.shape[0], bottom + padding)\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, label, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        return frame\n",
    "\n",
    "    def capture_images(self, num_images=10, person_name=None):\n",
    "        if person_name:\n",
    "            output_dir = os.path.join(self.dataset_path, person_name)\n",
    "        else:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            output_dir = os.path.join(self.dataset_path, f\"person_{timestamp}\")\n",
    "        \n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        print(f\"üìÅ L∆∞u ·∫£nh khu√¥n m·∫∑t v√†o th∆∞ m·ª•c: {output_dir}\")\n",
    "\n",
    "        video = cv2.VideoCapture(0)\n",
    "        if not video.isOpened():\n",
    "            print(\"‚ùå Kh√¥ng th·ªÉ m·ªü webcam\")\n",
    "            return\n",
    "\n",
    "        print(f\"üöÄ B·∫Øt ƒë·∫ßu ch·ª•p {num_images} ·∫£nh khu√¥n m·∫∑t...\")\n",
    "        count = 0\n",
    "        while count < num_images:\n",
    "            ret, frame = video.read()\n",
    "            if not ret:\n",
    "                print(\"‚ùå Kh√¥ng th·ªÉ l·∫•y khung h√¨nh t·ª´ webcam\")\n",
    "                break\n",
    "\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            face_locations = face_recognition.face_locations(rgb_frame, model=self.detection_method)\n",
    "\n",
    "            if face_locations:\n",
    "                top, right, bottom, left = face_locations[0]\n",
    "                padding = 0\n",
    "                top_padded = max(0, top - padding)\n",
    "                left_padded = max(0, left - padding)\n",
    "                right_padded = min(frame.shape[1], right + padding)\n",
    "                bottom_padded = min(frame.shape[0], bottom + padding)\n",
    "\n",
    "                face_img = frame[top_padded:bottom_padded, left_padded:right_padded]\n",
    "                face_img_rgb = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)\n",
    "                face_img_pil = Image.fromarray(face_img_rgb)\n",
    "\n",
    "                result, _ = predict(self.model, face_img_pil, self.reference_images, self.transform, self.label_to_idx, self.device)\n",
    "                frame = self.draw_rectangles(frame, top, right, bottom, left, label=result)\n",
    "\n",
    "                filename = f\"face_{count:05d}.png\"\n",
    "                filepath = os.path.join(output_dir, filename)\n",
    "                cv2.imwrite(filepath, face_img)\n",
    "                print(f\"üì∏ ƒê√£ l∆∞u khu√¥n m·∫∑t th·ª© {count + 1}/{num_images}: {filepath}\")\n",
    "                count += 1\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t trong khung h√¨nh th·ª© {count + 1}\")\n",
    "                cv2.imshow(\"Face Detection\", frame)\n",
    "\n",
    "            cv2.imshow(\"Face Detection\", frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                print(\"üõë Ng∆∞·ªùi d√πng ƒë√£ tho√°t\")\n",
    "                break\n",
    "            time.sleep(1)\n",
    "\n",
    "        video.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(f\"‚úÖ Ho√†n t·∫•t! ƒê√£ l∆∞u {count} ·∫£nh khu√¥n m·∫∑t v√†o {output_dir}\")\n",
    "\n",
    "    def recognize_faces(self):\n",
    "        video = cv2.VideoCapture(0)\n",
    "        if not video.isOpened():\n",
    "            print(\"‚ùå Kh√¥ng th·ªÉ m·ªü webcam\")\n",
    "            return\n",
    "\n",
    "        print(\"üöÄ B·∫Øt ƒë·∫ßu nh·∫≠n di·ªán khu√¥n m·∫∑t t·ª´ webcam...\")\n",
    "        while True:\n",
    "            ret, frame = video.read()\n",
    "            if not ret:\n",
    "                print(\"‚ùå Kh√¥ng th·ªÉ l·∫•y khung h√¨nh t·ª´ webcam\")\n",
    "                break\n",
    "\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            face_locations = face_recognition.face_locations(rgb_frame, model=self.detection_method)\n",
    "\n",
    "            for top, right, bottom, left in face_locations:\n",
    "                padding = 0\n",
    "                top_padded = max(0, top - padding)\n",
    "                left_padded = max(0, left - padding)\n",
    "                right_padded = min(frame.shape[1], right + padding)\n",
    "                bottom_padded = min(frame.shape[0], bottom + padding)\n",
    "\n",
    "                face_img = frame[top_padded:bottom_padded, left_padded:right_padded]\n",
    "                face_img_rgb = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)\n",
    "                face_img_pil = Image.fromarray(face_img_rgb)\n",
    "\n",
    "                result, _ = predict(self.model, face_img_pil, self.reference_images, self.transform, self.label_to_idx, self.device)\n",
    "                frame = self.draw_rectangles(frame, top, right, bottom, left, label=result)\n",
    "\n",
    "            cv2.imshow(\"Face Recognition\", frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                print(\"üõë Ng∆∞·ªùi d√πng ƒë√£ tho√°t\")\n",
    "                break\n",
    "\n",
    "        video.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    frs = FaceRecognitionSystem(dataset_path=r\"C:\\Users\\Divu\\Desktop\\DADN\\detect_face\\extracted_faces\", model_path=r\"siamese_face_recognition_simple_cnn.pth\")\n",
    "    mode = input(\"Ch·ªçn ch·∫ø ƒë·ªô (1: Ch·ª•p ·∫£nh, 2: Nh·∫≠n di·ªán): \").strip()\n",
    "    if mode == \"1\":\n",
    "        person_name = input(\"Nh·∫≠p t√™n ng∆∞·ªùi (ho·∫∑c ƒë·ªÉ tr·ªëng ƒë·ªÉ d√πng timestamp): \").strip()\n",
    "        frs.capture_images(num_images=10, person_name=person_name if person_name else None)\n",
    "    elif mode == \"2\":\n",
    "        frs.recognize_faces()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
