{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a4e5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import os\n",
    "from PIL import Image\n",
    "import glob\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "# ƒê·ªãnh nghƒ©a dataset\n",
    "class FaceRecognitionDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.label_to_idx = {}\n",
    "        \n",
    "        folders = [f for f in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, f))]\n",
    "        for idx, folder in enumerate(sorted(folders)):\n",
    "            self.label_to_idx[folder] = idx\n",
    "            image_files = glob.glob(os.path.join(root_dir, folder, \"*.jpg\")) + \\\n",
    "                         glob.glob(os.path.join(root_dir, folder, \"*.png\"))\n",
    "            for img_path in image_files:\n",
    "                self.image_paths.append(img_path)\n",
    "                self.labels.append(idx)\n",
    "        \n",
    "        self.num_classes = len(self.label_to_idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "# H√†m hu·∫•n luy·ªán m√¥ h√¨nh\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs=5, device='cuda'):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(dataloader):.4f}, Accuracy: {accuracy:.2f}%')\n",
    "    \n",
    "    # L∆∞u m√¥ h√¨nh\n",
    "    torch.save(model.state_dict(), 'face_recognition_model.pth')\n",
    "    print(\"‚úÖ M√¥ h√¨nh ResNet18 ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o 'face_recognition_model.pth'\")\n",
    "\n",
    "# H√†m ƒë√°nh gi√° m√¥ h√¨nh\n",
    "def evaluate_model(model, dataloader, device='cuda'):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # T√≠nh F1 score, precision, recall\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    # In b√°o c√°o chi ti·∫øt\n",
    "    print(\"Classification Report:\")\n",
    "    label_to_idx = dataloader.dataset.label_to_idx\n",
    "    idx_to_label = {v: k for k, v in label_to_idx.items()}\n",
    "    target_names = [idx_to_label[i] for i in range(len(label_to_idx))]\n",
    "    print(classification_report(all_labels, all_preds, target_names=target_names))\n",
    "    \n",
    "    return f1, precision, recall\n",
    "\n",
    "# Thi·∫øt l·∫≠p v√† hu·∫•n luy·ªán\n",
    "if __name__ == \"__main__\":\n",
    "    # Thi·∫øt l·∫≠p device\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    # T·∫°o dataset v√† dataloader cho t·∫≠p hu·∫•n luy·ªán\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # ResNet18 y√™u c·∫ßu k√≠ch th∆∞·ªõc 224x224\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Chu·∫©n h√≥a ImageNet\n",
    "    ])\n",
    "    train_dataset = FaceRecognitionDataset(root_dir=r\"C:\\Users\\Divu\\Desktop\\DADN\\detect_face\\extracted_faces\", transform=transform)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    # Kh·ªüi t·∫°o m√¥ h√¨nh ResNet18\n",
    "    model = models.resnet18(pretrained=False)  # Kh√¥ng s·ª≠ d·ª•ng pretrained\n",
    "    model.fc = nn.Linear(model.fc.in_features, train_dataset.num_classes)  # ƒêi·ªÅu ch·ªânh l·ªõp cu·ªëi\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Hu·∫•n luy·ªán m√¥ h√¨nh\n",
    "    train_model(model, train_dataloader, criterion, optimizer, num_epochs=5, device=device)\n",
    "\n",
    "    # ƒê√°nh gi√° tr√™n t·∫≠p hu·∫•n luy·ªán\n",
    "    print(\"\\nƒê√°nh gi√° tr√™n t·∫≠p hu·∫•n luy·ªán:\")\n",
    "    f1, precision, recall = evaluate_model(model, train_dataloader, device)\n",
    "    print(f\"F1 Score: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
    "\n",
    "    # T·∫°o dataset v√† dataloader cho t·∫≠p test\n",
    "    test_dataset = FaceRecognitionDataset(root_dir=r\"C:\\Users\\Divu\\Desktop\\DADN\\detect_face\\extracted_faces\", transform=transform)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # ƒê√°nh gi√° tr√™n t·∫≠p test\n",
    "    print(\"\\nƒê√°nh gi√° tr√™n t·∫≠p test:\")\n",
    "    f1, precision, recall = evaluate_model(model, test_dataloader, device)\n",
    "    print(f\"F1 Score: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84e1a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "from datetime import datetime\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torchvision import transforms, models\n",
    "\n",
    "def predict(model, image, transform, label_to_idx, device='cuda', threshold=0.5):\n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        image = transform(image).unsqueeze(0).to(device)\n",
    "        output = model(image)\n",
    "        probabilities = torch.softmax(output, dim=1)\n",
    "        max_prob, predicted = torch.max(probabilities, 1)\n",
    "        if max_prob.item() < threshold:\n",
    "            result = \"Unknown\"\n",
    "        else:\n",
    "            idx_to_label = {v: k for k, v in label_to_idx.items()}\n",
    "            result = f\"{idx_to_label[predicted.item()]} (Prob: {max_prob.item():.4f})\"\n",
    "    end_time = time.time()\n",
    "    inference_time = end_time - start_time\n",
    "    return result, inference_time\n",
    "\n",
    "class FaceRecognitionSystem:\n",
    "    def __init__(self, dataset_path=r\"C:\\Users\\Divu\\Desktop\\DADN\\detect_face\\extracted_faces\", detection_method=\"hog\", model_path=\"face_recognition_model_res_net.pth\"):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.detection_method = detection_method\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "        # Transform cho ResNet18\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),  # ResNet18 y√™u c·∫ßu k√≠ch th∆∞·ªõc 224x224\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Chu·∫©n h√≥a ImageNet\n",
    "        ])\n",
    "        \n",
    "        # T·∫°o danh s√°ch nh√£n\n",
    "        self.label_to_idx = {}\n",
    "        folders = [f for f in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, f))]\n",
    "        for idx, folder in enumerate(sorted(folders)):\n",
    "            self.label_to_idx[folder] = idx\n",
    "        self.num_classes = len(self.label_to_idx)\n",
    "        \n",
    "        # Kh·ªüi t·∫°o m√¥ h√¨nh ResNet18\n",
    "        self.model = models.resnet18(pretrained=False)  # Kh√¥ng s·ª≠ d·ª•ng pretrained\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, self.num_classes)  # ƒêi·ªÅu ch·ªânh l·ªõp cu·ªëi\n",
    "        self.model = self.model.to(self.device)\n",
    "        \n",
    "        # T·∫£i tr·∫°ng th√°i m√¥ h√¨nh\n",
    "        try:\n",
    "            self.model.load_state_dict(torch.load(model_path, map_location=self.device))\n",
    "            self.model.eval()\n",
    "            print(f\"‚úÖ M√¥ h√¨nh ResNet18 ƒë√£ ƒë∆∞·ª£c t·∫£i t·ª´ {model_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå L·ªói khi t·∫£i m√¥ h√¨nh: {e}\")\n",
    "            print(\"Vui l√≤ng hu·∫•n luy·ªán l·∫°i m√¥ h√¨nh ResNet18 v·ªõi dataset hi·ªán t·∫°i.\")\n",
    "\n",
    "    def draw_rectangles(self, frame, top, right, bottom, left, label=\"Face\"):\n",
    "        padding = 20\n",
    "        top = max(0, top - padding)\n",
    "        left = max(0, left - padding)\n",
    "        right = min(frame.shape[1], right + padding)\n",
    "        bottom = min(frame.shape[0], bottom + padding)\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, label, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        return frame\n",
    "\n",
    "    def capture_images(self, num_images=10, person_name=None):\n",
    "        if person_name:\n",
    "            output_dir = os.path.join(self.dataset_path, person_name)\n",
    "        else:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            output_dir = os.path.join(self.dataset_path, f\"person_{timestamp}\")\n",
    "        \n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        print(f\"üìÅ L∆∞u ·∫£nh khu√¥n m·∫∑t v√†o th∆∞ m·ª•c: {output_dir}\")\n",
    "\n",
    "        video = cv2.VideoCapture(0)\n",
    "        if not video.isOpened():\n",
    "            print(\"‚ùå Kh√¥ng th·ªÉ m·ªü webcam\")\n",
    "            return\n",
    "\n",
    "        print(f\"üöÄ B·∫Øt ƒë·∫ßu ch·ª•p {num_images} ·∫£nh khu√¥n m·∫∑t...\")\n",
    "        count = 0\n",
    "        while count < num_images:\n",
    "            ret, frame = video.read()\n",
    "            if not ret:\n",
    "                print(\"‚ùå Kh√¥ng th·ªÉ l·∫•y khung h√¨nh t·ª´ webcam\")\n",
    "                break\n",
    "\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            face_locations = face_recognition.face_locations(rgb_frame, model=self.detection_method)\n",
    "\n",
    "            if face_locations:\n",
    "                top, right, bottom, left = face_locations[0]\n",
    "                padding = 30\n",
    "                top = max(0, top - padding)\n",
    "                left = max(0, left - padding)\n",
    "                right = min(frame.shape[1], right + padding)\n",
    "                bottom = min(frame.shape[0], bottom + padding)\n",
    "\n",
    "                face_img = frame[top:bottom, left:right]\n",
    "                face_img_rgb = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)\n",
    "                face_img_pil = Image.fromarray(face_img_rgb)\n",
    "\n",
    "                result, _ = predict(self.model, face_img_pil, self.transform, self.label_to_idx, self.device)\n",
    "                frame = self.draw_rectangles(frame, top, right, bottom, left, label=result)\n",
    "\n",
    "                filename = f\"face_{count:05d}.png\"\n",
    "                filepath = os.path.join(output_dir, filename)\n",
    "                cv2.imwrite(filepath, face_img)\n",
    "                print(f\"üì∏ ƒê√£ l∆∞u khu√¥n m·∫∑t th·ª© {count + 1}/{num_images}: {filepath}\")\n",
    "                count += 1\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t trong khung h√¨nh th·ª© {count + 1}\")\n",
    "                cv2.imshow(\"Face Detection\", frame)\n",
    "\n",
    "            cv2.imshow(\"Face Detection\", frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                print(\"üõë Ng∆∞·ªùi d√πng ƒë√£ tho√°t\")\n",
    "                break\n",
    "            time.sleep(1)\n",
    "\n",
    "        video.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(f\"‚úÖ Ho√†n t·∫•t! ƒê√£ l∆∞u {count} ·∫£nh khu√¥n m·∫∑t v√†o {output_dir}\")\n",
    "\n",
    "    def recognize_faces(self):\n",
    "        video = cv2.VideoCapture(0)\n",
    "        if not video.isOpened():\n",
    "            print(\"‚ùå Kh√¥ng th·ªÉ m·ªü webcam\")\n",
    "            return\n",
    "\n",
    "        print(\"üöÄ B·∫Øt ƒë·∫ßu nh·∫≠n di·ªán khu√¥n m·∫∑t t·ª´ webcam...\")\n",
    "        while True:\n",
    "            ret, frame = video.read()\n",
    "            if not ret:\n",
    "                print(\"‚ùå Kh√¥ng th·ªÉ l·∫•y khung h√¨nh t·ª´ webcam\")\n",
    "                break\n",
    "\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            face_locations = face_recognition.face_locations(rgb_frame, model=self.detection_method)\n",
    "\n",
    "            for top, right, bottom, left in face_locations:\n",
    "                padding = 30\n",
    "                top_padded = max(0, top - padding)\n",
    "                left_padded = max(0, left - padding)\n",
    "                right_padded = min(frame.shape[1], right + padding)\n",
    "                bottom_padded = min(frame.shape[0], bottom + padding)\n",
    "\n",
    "                face_img = frame[top_padded:bottom_padded, left_padded:right_padded]\n",
    "                face_img_rgb = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)\n",
    "                face_img_pil = Image.fromarray(face_img_rgb)\n",
    "\n",
    "                result, _ = predict(self.model, face_img_pil, self.transform, self.label_to_idx, self.device)\n",
    "                frame = self.draw_rectangles(frame, top, right, bottom, left, label=result)\n",
    "\n",
    "            cv2.imshow(\"Face Recognition\", frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                print(\"üõë Ng∆∞·ªùi d√πng ƒë√£ tho√°t\")\n",
    "                break\n",
    "\n",
    "        video.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    frs = FaceRecognitionSystem(dataset_path=r\"C:\\Users\\Divu\\Desktop\\DADN\\detect_face\\extracted_faces\", model_path=r\"C:\\Users\\Divu\\Desktop\\DADN\\detect_face\\face_recognition_model_res_net.pth\")\n",
    "    mode = input(\"Ch·ªçn ch·∫ø ƒë·ªô (1: Ch·ª•p ·∫£nh, 2: Nh·∫≠n di·ªán): \").strip()\n",
    "    if mode == \"1\":\n",
    "        person_name = input(\"Nh·∫≠p t√™n ng∆∞·ªùi (ho·∫∑c ƒë·ªÉ tr·ªëng ƒë·ªÉ d√πng timestamp): \").strip()\n",
    "        frs.capture_images(num_images=10, person_name=person_name if person_name else None)\n",
    "    elif mode == \"2\":\n",
    "        frs.recognize_faces()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
