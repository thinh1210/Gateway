{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b18def8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import os\n",
    "from PIL import Image\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report\n",
    "import time\n",
    "\n",
    "# Định nghĩa backbone CNN đơn giản\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),  # Input: 3x224x224 -> Output: 32x224x224\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),       # Output: 32x112x112\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1), # Output: 64x112x112\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),       # Output: 64x56x56\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),# Output: 128x56x56\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)        # Output: 128x28x28\n",
    "        )\n",
    "        self.fc = nn.Linear(128 * 28 * 28, 128)  # Giảm chiều về vector 128\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Định nghĩa Siamese Network với backbone đơn giản\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.backbone = SimpleCNN()\n",
    "\n",
    "    def forward_one(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.forward_one(input1)\n",
    "        output2 = self.forward_one(input2)\n",
    "        return output1, output2\n",
    "\n",
    "# Hàm Contrastive Loss\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = torch.nn.functional.pairwise_distance(output1, output2)\n",
    "        loss_same = label * torch.pow(euclidean_distance, 2)\n",
    "        loss_diff = (1 - label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)\n",
    "        loss = torch.mean(loss_same + loss_diff) / 2\n",
    "        return loss, euclidean_distance\n",
    "\n",
    "# Định nghĩa dataset cho Siamese Network\n",
    "class SiameseFaceDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.label_to_idx = {}\n",
    "        \n",
    "        folders = [f for f in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, f))]\n",
    "        for idx, folder in enumerate(sorted(folders)):\n",
    "            self.label_to_idx[folder] = idx\n",
    "            image_files = glob.glob(os.path.join(root_dir, folder, \"*.jpg\")) + \\\n",
    "                         glob.glob(os.path.join(root_dir, folder, \"*.png\"))\n",
    "            for img_path in image_files:\n",
    "                self.image_paths.append(img_path)\n",
    "                self.labels.append(idx)\n",
    "        \n",
    "        self.num_classes = len(self.label_to_idx)\n",
    "        self.label_to_images = {i: [] for i in range(self.num_classes)}\n",
    "        for img_path, label in zip(self.image_paths, self.labels):\n",
    "            self.label_to_images[label].append(img_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths) * 2\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img1_idx = random.randint(0, len(self.image_paths) - 1)\n",
    "        img1_path = self.image_paths[img1_idx]\n",
    "        label1 = self.labels[img1_idx]\n",
    "        img1 = Image.open(img1_path).convert('RGB')\n",
    "\n",
    "        should_get_same_class = random.randint(0, 1)\n",
    "        if should_get_same_class:\n",
    "            same_class_images = self.label_to_images[label1]\n",
    "            img2_path = random.choice(same_class_images)\n",
    "            label = 1\n",
    "        else:\n",
    "            different_class = random.choice([l for l in range(self.num_classes) if l != label1])\n",
    "            img2_path = random.choice(self.label_to_images[different_class])\n",
    "            label = 0\n",
    "\n",
    "        img2 = Image.open(img2_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "\n",
    "        return img1, img2, torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "# Hàm huấn luyện Siamese Network\n",
    "def train_siamese_model(model, dataloader, criterion, optimizer, num_epochs=5, device='cuda'):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for img1, img2, labels in dataloader:\n",
    "            img1, img2, labels = img1.to(device), img2.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output1, output2 = model(img1, img2)\n",
    "            loss, distances = criterion(output1, output2, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            # Tính accuracy dựa trên ngưỡng khoảng cách\n",
    "            predictions = (distances < 0.8).float()  # Ngưỡng 0.8 để phân loại\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(dataloader)\n",
    "        epoch_acc = 100 * correct / total\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accuracies.append(epoch_acc)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%')\n",
    "    \n",
    "    # Lưu mô hình\n",
    "    torch.save(model.state_dict(), 'siamese_face_recognition_model.pth')\n",
    "    print(\"✅ Mô hình Siamese Network đã được lưu vào 'siamese_face_recognition_model.pth'\")\n",
    "    \n",
    "    return train_losses, train_accuracies\n",
    "\n",
    "# Hàm đánh giá Siamese Network\n",
    "def evaluate_siamese_model(model, dataloader, device='cuda'):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for img1, img2, labels in dataloader:\n",
    "            img1, img2, labels = img1.to(device), img2.to(device), labels.to(device)\n",
    "            output1, output2 = model(img1, img2)\n",
    "            _, distances = ContrastiveLoss()(output1, output2, labels)\n",
    "            predictions = (distances < 1.0).float()\n",
    "            all_preds.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=['Different', 'Same']))\n",
    "    \n",
    "    return f1, precision, recall\n",
    "\n",
    "# Hàm dự đoán cho một ảnh\n",
    "def predict_siamese(model, image, reference_images, transform, label_to_idx, device='cuda', threshold=1.0):\n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "    idx_to_label = {v: k for k, v in label_to_idx.items()}\n",
    "    min_distance = float('inf')\n",
    "    predicted_label = \"Unknown\"\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "        feature1 = model.forward_one(image_tensor)\n",
    "        \n",
    "        for ref_img_path, ref_label in reference_images:\n",
    "            ref_img = Image.open(ref_img_path).convert('RGB')\n",
    "            ref_tensor = transform(ref_img).unsqueeze(0).to(device)\n",
    "            feature2 = model.forward_one(ref_tensor)\n",
    "            distance = torch.nn.functional.pairwise_distance(feature1, feature2).item()\n",
    "            \n",
    "            if distance < min_distance and distance < threshold:\n",
    "                min_distance = distance\n",
    "                predicted_label = idx_to_label[ref_label]\n",
    "    \n",
    "    end_time = time.time()\n",
    "    inference_time = end_time - start_time\n",
    "    return predicted_label, min_distance, inference_time\n",
    "\n",
    "# Hàm dự đoán cho toàn bộ ảnh trong một thư mục\n",
    "def predict_siamese_folder(model, folder_path, reference_images, transform, label_to_idx, device='cuda', threshold=1.0):\n",
    "    print(f\"\\nPredicting images in folder: {folder_path}\")\n",
    "    \n",
    "    image_files = glob.glob(os.path.join(folder_path, \"*.jpg\")) + \\\n",
    "                  glob.glob(os.path.join(folder_path, \"*.png\"))\n",
    "    \n",
    "    if not image_files:\n",
    "        print(\"No images found in the folder. Please check the directory.\")\n",
    "        return\n",
    "    \n",
    "    results = []\n",
    "    total_inference_time = 0.0\n",
    "    prediction_counts = {}\n",
    "\n",
    "    for img_path in image_files:\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            result, distance, inference_time = predict_siamese(model, img, reference_images, transform, label_to_idx, device, threshold)\n",
    "            \n",
    "            print(f\"Image: {os.path.basename(img_path)}\")\n",
    "            print(f\"Prediction: {result} (Distance: {distance:.4f})\")\n",
    "            print(f\"Inference time: {inference_time:.6f} seconds\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            results.append((img_path, result, inference_time))\n",
    "            total_inference_time += inference_time\n",
    "            prediction_counts[result] = prediction_counts.get(result, 0) + 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {e}\")\n",
    "    \n",
    "    print(\"\\nSummary:\")\n",
    "    print(f\"Total images processed: {len(results)}\")\n",
    "    print(f\"Average inference time: {total_inference_time / len(results):.6f} seconds\")\n",
    "    print(\"\\nPrediction counts:\")\n",
    "    for label, count in prediction_counts.items():\n",
    "        print(f\"{label}: {count} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a83da81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.0304, Accuracy: 89.07%\n",
      "Epoch 2/10, Loss: 0.0266, Accuracy: 98.91%\n",
      "Epoch 3/10, Loss: 0.0139, Accuracy: 99.55%\n",
      "Epoch 4/10, Loss: 0.0091, Accuracy: 99.82%\n",
      "Epoch 5/10, Loss: 0.0051, Accuracy: 99.95%\n",
      "Epoch 6/10, Loss: 0.0043, Accuracy: 99.97%\n",
      "Epoch 7/10, Loss: 0.0029, Accuracy: 100.00%\n",
      "Epoch 8/10, Loss: 0.0027, Accuracy: 99.97%\n",
      "Epoch 9/10, Loss: 0.0019, Accuracy: 100.00%\n",
      "Epoch 10/10, Loss: 0.0016, Accuracy: 100.00%\n",
      "✅ Mô hình Siamese Network đã được lưu vào 'siamese_face_recognition_model.pth'\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Đánh giá trên tập huấn luyện:\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Different       1.00      1.00      1.00      1976\n",
      "        Same       1.00      1.00      1.00      1984\n",
      "\n",
      "    accuracy                           1.00      3960\n",
      "   macro avg       1.00      1.00      1.00      3960\n",
      "weighted avg       1.00      1.00      1.00      3960\n",
      "\n",
      "F1 Score: 1.0000, Precision: 1.0000, Recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from torchvision import transforms\n",
    "\n",
    "# Giả định rằng SiameseNetwork, SiameseFaceDataset, ContrastiveLoss, train_siamese_model, và evaluate_siamese_model đã được định nghĩa\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Thiết lập device\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    # Transform cho ảnh\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Tạo dataset và dataloader\n",
    "    dataset = SiameseFaceDataset(root_dir=r\"C:\\Users\\Divu\\Desktop\\DADN\\detect_face\\extracted_faces\", transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    # Khởi tạo mô hình và các thành phần\n",
    "    model = SiameseNetwork().to(device)\n",
    "    criterion = ContrastiveLoss(margin=2.0)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Huấn luyện mô hình\n",
    "    train_losses, train_accuracies = train_siamese_model(model, dataloader, criterion, optimizer, num_epochs=10, device=device)\n",
    "    \n",
    "    # Vẽ biểu đồ loss và accuracy trong cùng một khung hình\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "    \n",
    "    # Biểu đồ Loss trên trục y bên trái\n",
    "    ax1.plot(range(1, len(train_losses)+1), train_losses, 'r-', label='Training Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss', color='r')\n",
    "    ax1.tick_params(axis='y', labelcolor='r')\n",
    "    ax1.grid(True)\n",
    "    ax1.legend(loc='upper left')\n",
    "    \n",
    "    # Biểu đồ Accuracy trên trục y bên phải\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(range(1, len(train_accuracies)+1), train_accuracies, 'b-', label='Training Accuracy')\n",
    "    ax2.set_ylabel('Accuracy (%)', color='b')\n",
    "    ax2.tick_params(axis='y', labelcolor='b')\n",
    "    ax2.legend(loc='upper right')\n",
    "    \n",
    "    plt.title('Training Loss and Accuracy over Epochs')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Đánh giá mô hình\n",
    "    print(\"\\nĐánh giá trên tập huấn luyện:\")\n",
    "    f1, precision, recall = evaluate_siamese_model(model, dataloader, device)\n",
    "    print(f\"F1 Score: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
    "    \n",
    "    # Chuẩn bị ảnh tham chiếu (reference images) cho dự đoán\n",
    "    reference_images = []\n",
    "    for label, img_paths in dataset.label_to_images.items():\n",
    "        # Chọn một ảnh đại diện cho mỗi nhãn\n",
    "        reference_images.append((random.choice(img_paths), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78d34e36",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 249\u001b[39m\n\u001b[32m    246\u001b[39m optimizer = optim.Adam(model.parameters(), lr=\u001b[32m0.001\u001b[39m)\n\u001b[32m    248\u001b[39m \u001b[38;5;66;03m# Huấn luyện mô hình\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m \u001b[43mtrain_siamese_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# Đánh giá mô hình\u001b[39;00m\n\u001b[32m    252\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mĐánh giá trên tập huấn luyện:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 121\u001b[39m, in \u001b[36mtrain_siamese_model\u001b[39m\u001b[34m(model, dataloader, criterion, optimizer, num_epochs, device)\u001b[39m\n\u001b[32m    119\u001b[39m correct = \u001b[32m0\u001b[39m\n\u001b[32m    120\u001b[39m total = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimg1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimg1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg1\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Divu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Divu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Divu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 94\u001b[39m, in \u001b[36mSiameseFaceDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     92\u001b[39m img1_path = \u001b[38;5;28mself\u001b[39m.image_paths[img1_idx]\n\u001b[32m     93\u001b[39m label1 = \u001b[38;5;28mself\u001b[39m.labels[img1_idx]\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m img1 = \u001b[43mImage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg1_path\u001b[49m\u001b[43m)\u001b[49m.convert(\u001b[33m'\u001b[39m\u001b[33mRGB\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     96\u001b[39m should_get_same_class = random.randint(\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m should_get_same_class:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Divu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\PIL\\Image.py:3469\u001b[39m, in \u001b[36mopen\u001b[39m\u001b[34m(fp, mode, formats)\u001b[39m\n\u001b[32m   3466\u001b[39m     filename = os.path.realpath(os.fspath(fp))\n\u001b[32m   3468\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[32m-> \u001b[39m\u001b[32m3469\u001b[39m     fp = \u001b[43mbuiltins\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   3470\u001b[39m     exclusive_fp = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   3471\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import os\n",
    "from PIL import Image\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report\n",
    "import time\n",
    "\n",
    "# Định nghĩa backbone CNN đơn giản\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),  # Input: 3x224x224 -> Output: 32x224x224\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),       # Output: 32x112x112\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1), # Output: 64x112x112\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),       # Output: 64x56x56\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),# Output: 128x56x56\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)        # Output: 128x28x28\n",
    "        )\n",
    "        self.fc = nn.Linear(128 * 28 * 28, 128)  # Giảm chiều về vector 128\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Định nghĩa Siamese Network với backbone đơn giản\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.backbone = SimpleCNN()\n",
    "\n",
    "    def forward_one(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.forward_one(input1)\n",
    "        output2 = self.forward_one(input2)\n",
    "        return output1, output2\n",
    "\n",
    "# Hàm Contrastive Loss\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = torch.nn.functional.pairwise_distance(output1, output2)\n",
    "        loss_same = label * torch.pow(euclidean_distance, 2)\n",
    "        loss_diff = (1 - label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)\n",
    "        loss = torch.mean(loss_same + loss_diff) / 2\n",
    "        return loss, euclidean_distance\n",
    "\n",
    "# Định nghĩa dataset cho Siamese Network\n",
    "class SiameseFaceDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.label_to_idx = {}\n",
    "        \n",
    "        folders = [f for f in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, f))]\n",
    "        for idx, folder in enumerate(sorted(folders)):\n",
    "            self.label_to_idx[folder] = idx\n",
    "            image_files = glob.glob(os.path.join(root_dir, folder, \"*.jpg\")) + \\\n",
    "                         glob.glob(os.path.join(root_dir, folder, \"*.png\"))\n",
    "            for img_path in image_files:\n",
    "                self.image_paths.append(img_path)\n",
    "                self.labels.append(idx)\n",
    "        \n",
    "        self.num_classes = len(self.label_to_idx)\n",
    "        self.label_to_images = {i: [] for i in range(self.num_classes)}\n",
    "        for img_path, label in zip(self.image_paths, self.labels):\n",
    "            self.label_to_images[label].append(img_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths) * 2\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img1_idx = random.randint(0, len(self.image_paths) - 1)\n",
    "        img1_path = self.image_paths[img1_idx]\n",
    "        label1 = self.labels[img1_idx]\n",
    "        img1 = Image.open(img1_path).convert('RGB')\n",
    "\n",
    "        should_get_same_class = random.randint(0, 1)\n",
    "        if should_get_same_class:\n",
    "            same_class_images = self.label_to_images[label1]\n",
    "            img2_path = random.choice(same_class_images)\n",
    "            label = 1\n",
    "        else:\n",
    "            different_class = random.choice([l for l in range(self.num_classes) if l != label1])\n",
    "            img2_path = random.choice(self.label_to_images[different_class])\n",
    "            label = 0\n",
    "\n",
    "        img2 = Image.open(img2_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "\n",
    "        return img1, img2, torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "# Hàm huấn luyện Siamese Network\n",
    "def train_siamese_model(model, dataloader, criterion, optimizer, num_epochs=5, device='cuda'):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for img1, img2, labels in dataloader:\n",
    "            img1, img2, labels = img1.to(device), img2.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output1, output2 = model(img1, img2)\n",
    "            loss, distances = criterion(output1, output2, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            predictions = (distances < 1.0).float()\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(dataloader):.4f}, Accuracy: {accuracy:.2f}%')\n",
    "    \n",
    "    torch.save(model.state_dict(), 'siamese_face_recognition_simple_cnn.pth')\n",
    "    print(\"✅ Mô hình Siamese Network đã được lưu vào 'siamese_face_recognition_simple_cnn.pth'\")\n",
    "\n",
    "# Hàm đánh giá Siamese Network\n",
    "def evaluate_siamese_model(model, dataloader, device='cuda'):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for img1, img2, labels in dataloader:\n",
    "            img1, img2, labels = img1.to(device), img2.to(device), labels.to(device)\n",
    "            output1, output2 = model(img1, img2)\n",
    "            _, distances = ContrastiveLoss()(output1, output2, labels)\n",
    "            predictions = (distances < 1.0).float()\n",
    "            all_preds.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=['Different', 'Same']))\n",
    "    \n",
    "    return f1, precision, recall\n",
    "\n",
    "# Hàm dự đoán cho một ảnh\n",
    "def predict_siamese(model, image, reference_images, transform, label_to_idx, device='cuda', threshold=1.0):\n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "    idx_to_label = {v: k for k, v in label_to_idx.items()}\n",
    "    min_distance = float('inf')\n",
    "    predicted_label = \"Unknown\"\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "        feature1 = model.forward_one(image_tensor)\n",
    "        \n",
    "        for ref_img_path, ref_label in reference_images:\n",
    "            ref_img = Image.open(ref_img_path).convert('RGB')\n",
    "            ref_tensor = transform(ref_img).unsqueeze(0).to(device)\n",
    "            feature2 = model.forward_one(ref_tensor)\n",
    "            distance = torch.nn.functional.pairwise_distance(feature1, feature2).item()\n",
    "            \n",
    "            if distance < min_distance and distance < threshold:\n",
    "                min_distance = distance\n",
    "                predicted_label = idx_to_label[ref_label]\n",
    "    \n",
    "    end_time = time.time()\n",
    "    inference_time = end_time - start_time\n",
    "    return predicted_label, min_distance, inference_time\n",
    "\n",
    "# Hàm dự đoán cho toàn bộ ảnh trong một thư mục\n",
    "def predict_siamese_folder(model, folder_path, reference_images, transform, label_to_idx, device='cuda', threshold=1.0):\n",
    "    print(f\"\\nPredicting images in folder: {folder_path}\")\n",
    "    \n",
    "    image_files = glob.glob(os.path.join(folder_path, \"*.jpg\")) + \\\n",
    "                  glob.glob(os.path.join(folder_path, \"*.png\"))\n",
    "    \n",
    "    if not image_files:\n",
    "        print(\"No images found in the folder. Please check the directory.\")\n",
    "        return\n",
    "    \n",
    "    results = []\n",
    "    total_inference_time = 0.0\n",
    "    prediction_counts = {}\n",
    "\n",
    "    for img_path in image_files:\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            result, distance, inference_time = predict_siamese(model, img, reference_images, transform, label_to_idx, device, threshold)\n",
    "            \n",
    "            print(f\"Image: {os.path.basename(img_path)}\")\n",
    "            print(f\"Prediction: {result} (Distance: {distance:.4f})\")\n",
    "            print(f\"Inference time: {inference_time:.6f} seconds\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            results.append((img_path, result, inference_time))\n",
    "            total_inference_time += inference_time\n",
    "            prediction_counts[result] = prediction_counts.get(result, 0) + 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {e}\")\n",
    "    \n",
    "    print(\"\\nSummary:\")\n",
    "    print(f\"Total images processed: {len(results)}\")\n",
    "    print(f\"Average inference time: {total_inference_time / len(results):.6f} seconds\")\n",
    "    print(\"\\nPrediction counts:\")\n",
    "    for label, count in prediction_counts.items():\n",
    "        print(f\"{label}: {count} images\")\n",
    "\n",
    "# Thiết lập và huấn luyện\n",
    "if __name__ == \"__main__\":\n",
    "    # Thiết lập device\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    # Transform cho ảnh\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Tạo dataset và dataloader\n",
    "    dataset = SiameseFaceDataset(root_dir=r\"C:\\Users\\Divu\\Desktop\\DADN\\detect_face\\extracted_faces\", transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    # Khởi tạo mô hình và các thành phần\n",
    "    model = SiameseNetwork().to(device)\n",
    "    criterion = ContrastiveLoss(margin=2.0)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Huấn luyện mô hình\n",
    "    train_siamese_model(model, dataloader, criterion, optimizer, num_epochs=10, device=device)\n",
    "    \n",
    "    # Đánh giá mô hình\n",
    "    print(\"\\nĐánh giá trên tập huấn luyện:\")\n",
    "    f1, precision, recall = evaluate_siamese_model(model, dataloader, device)\n",
    "    print(f\"F1 Score: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
    "    \n",
    "    # Chuẩn bị ảnh tham chiếu (reference images) cho dự đoán\n",
    "    reference_images = []\n",
    "    for label, img_paths in dataset.label_to_images.items():\n",
    "        reference_images.append((random.choice(img_paths), label))\n",
    "    \n",
    "    # Dự đoán trên thư mục test\n",
    "    test_folder = r\"C:\\Users\\Divu\\Desktop\\DADN\\detect_face\\test_faces\"\n",
    "    predict_siamese_folder(model, test_folder, reference_images, transform, dataset.label_to_idx, device, threshold=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b1ae3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Đánh giá trên tập huấn luyện:\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Different       1.00      1.00      1.00      1952\n",
      "        Same       1.00      1.00      1.00      1946\n",
      "\n",
      "    accuracy                           1.00      3898\n",
      "   macro avg       1.00      1.00      1.00      3898\n",
      "weighted avg       1.00      1.00      1.00      3898\n",
      "\n",
      "F1 Score: 1.0000, Precision: 1.0000, Recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Transform cho ảnh\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Tạo dataset và dataloader\n",
    "dataset = SiameseFaceDataset(root_dir=r\"C:\\Users\\Divu\\Desktop\\DADN\\detect_face\\extracted_faces\", transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Khởi tạo mô hình và các thành phần\n",
    "model = SiameseNetwork().to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(r\"C:\\Users\\Divu\\Desktop\\DADN\\detect_face\\siamese_face_recognition_simple_cnn.pth\"))\n",
    "model.eval()\n",
    "# Đánh giá mô hình\n",
    "print(\"\\nĐánh giá trên tập huấn luyện:\")\n",
    "f1, precision, recall = evaluate_siamese_model(model, dataloader, device)\n",
    "print(f\"F1 Score: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
    "\n",
    "# Chuẩn bị ảnh tham chiếu (reference images) cho dự đoán\n",
    "reference_images = []\n",
    "for label, img_paths in dataset.label_to_images.items():\n",
    "    reference_images.append((random.choice(img_paths), label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2ebdc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting images in folder: C:\\Users\\Divu\\Desktop\\DADN\\detect_face\\extracted_faces\\thinh2\n",
      "Image: face_00000.png\n",
      "Prediction: thinh2 (Distance: 0.3002)\n",
      "Inference time: 0.298390 seconds\n",
      "--------------------------------------------------\n",
      "Image: face_00001.png\n",
      "Prediction: thinh2 (Distance: 0.2535)\n",
      "Inference time: 0.018555 seconds\n",
      "--------------------------------------------------\n",
      "Image: face_00002.png\n",
      "Prediction: thinh2 (Distance: 0.5074)\n",
      "Inference time: 0.016562 seconds\n",
      "--------------------------------------------------\n",
      "Image: face_00003.png\n",
      "Prediction: thinh2 (Distance: 0.5213)\n",
      "Inference time: 0.016361 seconds\n",
      "--------------------------------------------------\n",
      "Image: face_00004.png\n",
      "Prediction: thinh2 (Distance: 0.2409)\n",
      "Inference time: 0.016016 seconds\n",
      "--------------------------------------------------\n",
      "Image: face_00005.png\n",
      "Prediction: thinh2 (Distance: 0.3802)\n",
      "Inference time: 0.014751 seconds\n",
      "--------------------------------------------------\n",
      "Image: face_00006.png\n",
      "Prediction: thinh2 (Distance: 0.2544)\n",
      "Inference time: 0.015620 seconds\n",
      "--------------------------------------------------\n",
      "Image: face_00007.png\n",
      "Prediction: thinh2 (Distance: 0.3396)\n",
      "Inference time: 0.016798 seconds\n",
      "--------------------------------------------------\n",
      "Image: face_00008.png\n",
      "Prediction: thinh2 (Distance: 0.2161)\n",
      "Inference time: 0.015784 seconds\n",
      "--------------------------------------------------\n",
      "Image: face_00009.png\n",
      "Prediction: thinh2 (Distance: 0.2339)\n",
      "Inference time: 0.014504 seconds\n",
      "--------------------------------------------------\n",
      "Image: face_00010.png\n",
      "Prediction: thinh2 (Distance: 0.2117)\n",
      "Inference time: 0.014455 seconds\n",
      "--------------------------------------------------\n",
      "Image: face_00011.png\n",
      "Prediction: thinh2 (Distance: 0.3243)\n",
      "Inference time: 0.016189 seconds\n",
      "--------------------------------------------------\n",
      "Image: face_00012.png\n",
      "Prediction: thinh2 (Distance: 0.2656)\n",
      "Inference time: 0.015903 seconds\n",
      "--------------------------------------------------\n",
      "Image: face_00013.png\n",
      "Prediction: thinh2 (Distance: 0.2394)\n",
      "Inference time: 0.016594 seconds\n",
      "--------------------------------------------------\n",
      "Image: face_00014.png\n",
      "Prediction: thinh2 (Distance: 0.2248)\n",
      "Inference time: 0.018843 seconds\n",
      "--------------------------------------------------\n",
      "Image: face_00015.png\n",
      "Prediction: thinh2 (Distance: 0.0000)\n",
      "Inference time: 0.013507 seconds\n",
      "--------------------------------------------------\n",
      "Image: face_00016.png\n",
      "Prediction: thinh2 (Distance: 0.1896)\n",
      "Inference time: 0.020298 seconds\n",
      "--------------------------------------------------\n",
      "Image: face_00017.png\n",
      "Prediction: thinh2 (Distance: 0.2975)\n",
      "Inference time: 0.015563 seconds\n",
      "--------------------------------------------------\n",
      "Image: face_00018.png\n",
      "Prediction: thinh2 (Distance: 0.3865)\n",
      "Inference time: 0.009647 seconds\n",
      "--------------------------------------------------\n",
      "Image: face_00019.png\n",
      "Prediction: thinh2 (Distance: 0.5820)\n",
      "Inference time: 0.019982 seconds\n",
      "--------------------------------------------------\n",
      "\n",
      "Summary:\n",
      "Total images processed: 20\n",
      "Average inference time: 0.030216 seconds\n",
      "\n",
      "Prediction counts:\n",
      "thinh2: 20 images\n"
     ]
    }
   ],
   "source": [
    "# Dự đoán trên thư mục test\n",
    "test_folder = r\"C:\\Users\\Divu\\Desktop\\DADN\\detect_face\\extracted_faces\\thinh2\"\n",
    "predict_siamese_folder(model, test_folder, reference_images, transform, dataset.label_to_idx, device, threshold=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c980e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting images in folder: C:\\Users\\Divu\\Desktop\\DADN\\detect_face\\extracted_faces\\Luan\n",
      "Image: face_00001_0.png\n",
      "Prediction: Luan (Distance: 0.2526)\n",
      "Inference time: 0.127573 seconds\n",
      "--------------------------------------------------\n",
      "Image: face_00003_0.png\n",
      "Prediction: Luan (Distance: 0.1859)\n",
      "Inference time: 0.018660 seconds\n",
      "--------------------------------------------------\n",
      "Image: face_00004_0.png\n",
      "Prediction: Luan (Distance: 0.1531)\n",
      "Inference time: 0.014708 seconds\n",
      "--------------------------------------------------\n",
      "Image: face_00005_0.png\n",
      "Prediction: Luan (Distance: 0.1746)\n",
      "Inference time: 0.016024 seconds\n",
      "--------------------------------------------------\n",
      "Image: face_00006_0.png\n",
      "Prediction: Luan (Distance: 0.2459)\n",
      "Inference time: 0.017016 seconds\n",
      "--------------------------------------------------\n",
      "Image: face_00007_0.png\n",
      "Prediction: Luan (Distance: 0.1130)\n",
      "Inference time: 0.014601 seconds\n",
      "--------------------------------------------------\n",
      "Image: face_00008_0.png\n",
      "Prediction: Luan (Distance: 0.3130)\n",
      "Inference time: 0.018631 seconds\n",
      "--------------------------------------------------\n",
      "Image: face_00009_0.png\n",
      "Prediction: Luan (Distance: 0.2602)\n",
      "Inference time: 0.018019 seconds\n",
      "--------------------------------------------------\n",
      "Image: face_00010_0.png\n",
      "Prediction: Luan (Distance: 0.1529)\n",
      "Inference time: 0.016576 seconds\n",
      "--------------------------------------------------\n",
      "Image: face_00011_0.png\n",
      "Prediction: Luan (Distance: 0.2207)\n",
      "Inference time: 0.015220 seconds\n",
      "--------------------------------------------------\n",
      "Image: face_00012_0.png\n",
      "Prediction: Luan (Distance: 0.1108)\n",
      "Inference time: 0.018591 seconds\n",
      "--------------------------------------------------\n",
      "Image: face_00013_0.png\n",
      "Prediction: Luan (Distance: 0.2157)\n",
      "Inference time: 0.016771 seconds\n",
      "--------------------------------------------------\n",
      "Image: face_00014_0.png\n",
      "Prediction: Luan (Distance: 0.1251)\n",
      "Inference time: 0.018270 seconds\n",
      "--------------------------------------------------\n",
      "Image: face_00015_0.png\n",
      "Prediction: Luan (Distance: 0.1648)\n",
      "Inference time: 0.016657 seconds\n",
      "--------------------------------------------------\n",
      "Image: face_00016_0.png\n",
      "Prediction: Luan (Distance: 0.0000)\n",
      "Inference time: 0.017398 seconds\n",
      "--------------------------------------------------\n",
      "Image: face_00017_0.png\n",
      "Prediction: Luan (Distance: 0.1891)\n",
      "Inference time: 0.015170 seconds\n",
      "--------------------------------------------------\n",
      "Image: face_00018_0.png\n",
      "Prediction: Luan (Distance: 0.1847)\n",
      "Inference time: 0.017738 seconds\n",
      "--------------------------------------------------\n",
      "Image: face_00019_0.png\n",
      "Prediction: Luan (Distance: 0.1283)\n",
      "Inference time: 0.014880 seconds\n",
      "--------------------------------------------------\n",
      "\n",
      "Summary:\n",
      "Total images processed: 18\n",
      "Average inference time: 0.022917 seconds\n",
      "\n",
      "Prediction counts:\n",
      "Luan: 18 images\n"
     ]
    }
   ],
   "source": [
    "# Dự đoán trên thư mục test\n",
    "test_folder = r\"C:\\Users\\Divu\\Desktop\\DADN\\detect_face\\extracted_faces\\Luan\"\n",
    "predict_siamese_folder(model, test_folder, reference_images, transform, dataset.label_to_idx, device, threshold=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a81445c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Mô hình Siamese Network đã được tải từ C:\\Users\\Divu\\Desktop\\DADN\\detect_face\\siamese_face_recognition_simple_cnn.pth\n",
      "🚀 Bắt đầu nhận diện khuôn mặt từ webcam...\n",
      "🛑 Người dùng đã thoát\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "from datetime import datetime\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import glob\n",
    "import random\n",
    "\n",
    "\n",
    "# Hàm dự đoán cho Siamese Network\n",
    "def predict(model, image, reference_images, transform, label_to_idx, device='cuda', threshold=0.8):\n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "    idx_to_label = {v: k for k, v in label_to_idx.items()}\n",
    "    min_distance = float('inf')\n",
    "    predicted_label = \"Unknown\"\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "        feature1 = model.forward_one(image_tensor)\n",
    "        \n",
    "        for ref_img_path, ref_label in reference_images:\n",
    "            ref_img = Image.open(ref_img_path).convert('RGB')\n",
    "            ref_tensor = transform(ref_img).unsqueeze(0).to(device)\n",
    "            feature2 = model.forward_one(ref_tensor)\n",
    "            distance = torch.nn.functional.pairwise_distance(feature1, feature2).item()\n",
    "            \n",
    "            if distance < min_distance and distance < threshold:\n",
    "                min_distance = distance\n",
    "                predicted_label = idx_to_label[ref_label]\n",
    "    \n",
    "    end_time = time.time()\n",
    "    inference_time = end_time - start_time\n",
    "    return predicted_label, inference_time\n",
    "\n",
    "class FaceRecognitionSystem:\n",
    "    def __init__(self, dataset_path=r\"C:\\Users\\Divu\\Desktop\\DADN\\detect_face\\extracted_faces\", detection_method=\"hog\", model_path=\"siamese_face_recognition_simple_cnn.pth\"):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.detection_method = detection_method\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "        # Transform cho ảnh\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        # Tạo danh sách nhãn và ảnh tham chiếu\n",
    "        self.label_to_idx = {}\n",
    "        self.reference_images = []\n",
    "        folders = [f for f in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, f))]\n",
    "        for idx, folder in enumerate(sorted(folders)):\n",
    "            self.label_to_idx[folder] = idx\n",
    "            # Chọn một ảnh tham chiếu ngẫu nhiên cho mỗi nhãn\n",
    "            image_files = glob.glob(os.path.join(dataset_path, folder, \"*.jpg\")) + \\\n",
    "                         glob.glob(os.path.join(dataset_path, folder, \"*.png\"))\n",
    "            if image_files:\n",
    "                self.reference_images.append((random.choice(image_files), idx))\n",
    "        \n",
    "        self.num_classes = len(self.label_to_idx)\n",
    "        \n",
    "        # Khởi tạo mô hình Siamese Network\n",
    "        self.model = SiameseNetwork().to(self.device)\n",
    "        \n",
    "        # Tải trạng thái mô hình\n",
    "        try:\n",
    "            self.model.load_state_dict(torch.load(model_path, map_location=self.device))\n",
    "            self.model.eval()\n",
    "            print(f\"✅ Mô hình Siamese Network đã được tải từ {model_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Lỗi khi tải mô hình: {e}\")\n",
    "            print(\"Vui lòng huấn luyện lại mô hình Siamese Network với dataset hiện tại.\")\n",
    "\n",
    "    def draw_rectangles(self, frame, top, right, bottom, left, label=\"Face\"):\n",
    "        padding = 0\n",
    "        top = max(0, top - padding)\n",
    "        left = max(0, left - padding)\n",
    "        right = min(frame.shape[1], right + padding)\n",
    "        bottom = min(frame.shape[0], bottom + padding)\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, label, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        return frame\n",
    "\n",
    "    def capture_images(self, num_images=10, person_name=None):\n",
    "        if person_name:\n",
    "            output_dir = os.path.join(self.dataset_path, person_name)\n",
    "        else:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            output_dir = os.path.join(self.dataset_path, f\"person_{timestamp}\")\n",
    "        \n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        print(f\"📁 Lưu ảnh khuôn mặt vào thư mục: {output_dir}\")\n",
    "\n",
    "        video = cv2.VideoCapture(0)\n",
    "        if not video.isOpened():\n",
    "            print(\"❌ Không thể mở webcam\")\n",
    "            return\n",
    "\n",
    "        print(f\"🚀 Bắt đầu chụp {num_images} ảnh khuôn mặt...\")\n",
    "        count = 0\n",
    "        while count < num_images:\n",
    "            ret, frame = video.read()\n",
    "            if not ret:\n",
    "                print(\"❌ Không thể lấy khung hình từ webcam\")\n",
    "                break\n",
    "\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            face_locations = face_recognition.face_locations(rgb_frame, model=self.detection_method)\n",
    "\n",
    "            if face_locations:\n",
    "                top, right, bottom, left = face_locations[0]\n",
    "                padding = 0\n",
    "                top_padded = max(0, top - padding)\n",
    "                left_padded = max(0, left - padding)\n",
    "                right_padded = min(frame.shape[1], right + padding)\n",
    "                bottom_padded = min(frame.shape[0], bottom + padding)\n",
    "\n",
    "                face_img = frame[top_padded:bottom_padded, left_padded:right_padded]\n",
    "                face_img_rgb = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)\n",
    "                face_img_pil = Image.fromarray(face_img_rgb)\n",
    "\n",
    "                result, _ = predict(self.model, face_img_pil, self.reference_images, self.transform, self.label_to_idx, self.device)\n",
    "                frame = self.draw_rectangles(frame, top, right, bottom, left, label=result)\n",
    "\n",
    "                filename = f\"face_{count:05d}.png\"\n",
    "                filepath = os.path.join(output_dir, filename)\n",
    "                cv2.imwrite(filepath, face_img)\n",
    "                print(f\"📸 Đã lưu khuôn mặt thứ {count + 1}/{num_images}: {filepath}\")\n",
    "                count += 1\n",
    "            else:\n",
    "                print(f\"⚠️ Không phát hiện khuôn mặt trong khung hình thứ {count + 1}\")\n",
    "                cv2.imshow(\"Face Detection\", frame)\n",
    "\n",
    "            cv2.imshow(\"Face Detection\", frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                print(\"🛑 Người dùng đã thoát\")\n",
    "                break\n",
    "            time.sleep(1)\n",
    "\n",
    "        video.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(f\"✅ Hoàn tất! Đã lưu {count} ảnh khuôn mặt vào {output_dir}\")\n",
    "\n",
    "    def recognize_faces(self):\n",
    "        video = cv2.VideoCapture(0)\n",
    "        if not video.isOpened():\n",
    "            print(\"❌ Không thể mở webcam\")\n",
    "            return\n",
    "\n",
    "        print(\"🚀 Bắt đầu nhận diện khuôn mặt từ webcam...\")\n",
    "        while True:\n",
    "            ret, frame = video.read()\n",
    "            if not ret:\n",
    "                print(\"❌ Không thể lấy khung hình từ webcam\")\n",
    "                break\n",
    "\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            face_locations = face_recognition.face_locations(rgb_frame, model=self.detection_method)\n",
    "\n",
    "            for top, right, bottom, left in face_locations:\n",
    "                padding = 0\n",
    "                top_padded = max(0, top - padding)\n",
    "                left_padded = max(0, left - padding)\n",
    "                right_padded = min(frame.shape[1], right + padding)\n",
    "                bottom_padded = min(frame.shape[0], bottom + padding)\n",
    "\n",
    "                face_img = frame[top_padded:bottom_padded, left_padded:right_padded]\n",
    "                face_img_rgb = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)\n",
    "                face_img_pil = Image.fromarray(face_img_rgb)\n",
    "\n",
    "                result, _ = predict(self.model, face_img_pil, self.reference_images, self.transform, self.label_to_idx, self.device)\n",
    "                frame = self.draw_rectangles(frame, top, right, bottom, left, label=result)\n",
    "\n",
    "            cv2.imshow(\"Face Recognition\", frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                print(\"🛑 Người dùng đã thoát\")\n",
    "                break\n",
    "\n",
    "        video.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    frs = FaceRecognitionSystem(dataset_path=r\"C:\\Users\\Divu\\Desktop\\DADN\\detect_face\\extracted_faces\", model_path=r\"C:\\Users\\Divu\\Desktop\\DADN\\detect_face\\siamese_face_recognition_simple_cnn.pth\")\n",
    "    mode = input(\"Chọn chế độ (1: Chụp ảnh, 2: Nhận diện): \").strip()\n",
    "    if mode == \"1\":\n",
    "        person_name = input(\"Nhập tên người (hoặc để trống để dùng timestamp): \").strip()\n",
    "        frs.capture_images(num_images=10, person_name=person_name if person_name else None)\n",
    "    elif mode == \"2\":\n",
    "        frs.recognize_faces()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
