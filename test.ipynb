{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0e835d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ LÆ°u áº£nh khuÃ´n máº·t vÃ o thÆ° má»¥c: dataset\\person_20250421_120105\n",
      "ğŸš€ Báº¯t Ä‘áº§u chá»¥p 10 áº£nh khuÃ´n máº·t...\n",
      "ğŸ“¸ ÄÃ£ lÆ°u khuÃ´n máº·t thá»© 1/10: dataset\\person_20250421_120105\\face_00000.png\n",
      "ğŸ“¸ ÄÃ£ lÆ°u khuÃ´n máº·t thá»© 2/10: dataset\\person_20250421_120105\\face_00001.png\n",
      "ğŸ“¸ ÄÃ£ lÆ°u khuÃ´n máº·t thá»© 3/10: dataset\\person_20250421_120105\\face_00002.png\n",
      "ğŸ“¸ ÄÃ£ lÆ°u khuÃ´n máº·t thá»© 4/10: dataset\\person_20250421_120105\\face_00003.png\n",
      "ğŸ“¸ ÄÃ£ lÆ°u khuÃ´n máº·t thá»© 5/10: dataset\\person_20250421_120105\\face_00004.png\n",
      "âš ï¸ KhÃ´ng phÃ¡t hiá»‡n khuÃ´n máº·t trong khung hÃ¬nh thá»© 6\n",
      "ğŸ“¸ ÄÃ£ lÆ°u khuÃ´n máº·t thá»© 6/10: dataset\\person_20250421_120105\\face_00005.png\n",
      "ğŸ“¸ ÄÃ£ lÆ°u khuÃ´n máº·t thá»© 7/10: dataset\\person_20250421_120105\\face_00006.png\n",
      "ğŸ“¸ ÄÃ£ lÆ°u khuÃ´n máº·t thá»© 8/10: dataset\\person_20250421_120105\\face_00007.png\n",
      "ğŸ“¸ ÄÃ£ lÆ°u khuÃ´n máº·t thá»© 9/10: dataset\\person_20250421_120105\\face_00008.png\n",
      "ğŸ“¸ ÄÃ£ lÆ°u khuÃ´n máº·t thá»© 10/10: dataset\\person_20250421_120105\\face_00009.png\n",
      "âœ… HoÃ n táº¥t! ÄÃ£ lÆ°u 10 áº£nh khuÃ´n máº·t vÃ o dataset\\person_20250421_120105\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "from datetime import datetime\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "\n",
    "class FaceRecognitionSystem:\n",
    "    def __init__(self, dataset_path=\"dataset\", detection_method=\"hog\"):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.detection_method = detection_method\n",
    "\n",
    "    def draw_rectangles(self, face_img, top, right, bottom, left):\n",
    "        \"\"\"Váº½ khung hÃ¬nh chá»¯ nháº­t quanh khuÃ´n máº·t trÃªn vÃ¹ng Ä‘Ã£ cáº¯t.\"\"\"\n",
    "        padding = 20  # Sá»‘ pixel má»Ÿ rá»™ng má»—i cáº¡nh\n",
    "        # Äiá»u chá»‰nh tá»a Ä‘á»™ tÆ°Æ¡ng Ä‘á»‘i cho vÃ¹ng Ä‘Ã£ cáº¯t\n",
    "        top_padded = padding\n",
    "        right_padded = face_img.shape[1] - padding\n",
    "        bottom_padded = face_img.shape[0] - padding\n",
    "        left_padded = padding\n",
    "        # Váº½ hÃ¬nh chá»¯ nháº­t\n",
    "        cv2.rectangle(face_img, (left_padded, top_padded), (right_padded, bottom_padded), (0, 255, 0), 2)\n",
    "        # Ghi nhÃ£n \"Face\"\n",
    "        cv2.putText(face_img, \"Face\", (left_padded, top_padded - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        return face_img\n",
    "\n",
    "    def capture_images(self, num_images=10, person_name=None):\n",
    "        \"\"\"Chá»¥p vÃ  lÆ°u chá»‰ vÃ¹ng khuÃ´n máº·t vá»›i khung hÃ¬nh chá»¯ nháº­t.\"\"\"\n",
    "        # Táº¡o tÃªn thÆ° má»¥c dá»±a trÃªn person_name hoáº·c timestamp\n",
    "        if person_name:\n",
    "            output_dir = os.path.join(self.dataset_path, person_name)\n",
    "        else:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            output_dir = os.path.join(self.dataset_path, f\"person_{timestamp}\")\n",
    "\n",
    "        # Táº¡o thÆ° má»¥c náº¿u chÆ°a tá»“n táº¡i\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        print(f\"ğŸ“ LÆ°u áº£nh khuÃ´n máº·t vÃ o thÆ° má»¥c: {output_dir}\")\n",
    "\n",
    "        # Khá»Ÿi táº¡o webcam\n",
    "        video = cv2.VideoCapture(0)\n",
    "        if not video.isOpened():\n",
    "            print(\"âŒ KhÃ´ng thá»ƒ má»Ÿ webcam\")\n",
    "            return\n",
    "\n",
    "        print(f\"ğŸš€ Báº¯t Ä‘áº§u chá»¥p {num_images} áº£nh khuÃ´n máº·t...\")\n",
    "        count = 0\n",
    "        while count < num_images:\n",
    "            ret, frame = video.read()\n",
    "            if not ret:\n",
    "                print(\"âŒ KhÃ´ng thá»ƒ láº¥y khung hÃ¬nh tá»« webcam\")\n",
    "                break\n",
    "\n",
    "            # Chuyá»ƒn khung hÃ¬nh sang RGB\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # PhÃ¡t hiá»‡n khuÃ´n máº·t\n",
    "            face_locations = face_recognition.face_locations(rgb_frame, model=self.detection_method)\n",
    "\n",
    "            # Náº¿u phÃ¡t hiá»‡n Ã­t nháº¥t má»™t khuÃ´n máº·t\n",
    "            if face_locations:\n",
    "                # Chá»‰ xá»­ lÃ½ khuÃ´n máº·t Ä‘áº§u tiÃªn (náº¿u cÃ³ nhiá»u khuÃ´n máº·t)\n",
    "                top, right, bottom, left = face_locations[0]\n",
    "                \n",
    "                # Má»Ÿ rá»™ng vÃ¹ng khuÃ´n máº·t vá»›i padding\n",
    "                padding = 30\n",
    "                top = max(0, top - padding)\n",
    "                left = max(0, left - padding)\n",
    "                right = min(frame.shape[1], right + padding)\n",
    "                bottom = min(frame.shape[0], bottom + padding)\n",
    "\n",
    "                # Cáº¯t vÃ¹ng khuÃ´n máº·t tá»« khung hÃ¬nh\n",
    "                face_img = frame[top:bottom, left:right]\n",
    "\n",
    "                # Váº½ khung hÃ¬nh chá»¯ nháº­t trÃªn vÃ¹ng khuÃ´n máº·t\n",
    "                face_img_with_boxes = self.draw_rectangles(face_img.copy(), top, right, bottom, left)\n",
    "\n",
    "                # LÆ°u áº£nh khuÃ´n máº·t vá»›i khung\n",
    "                filename = f\"face_{count:05d}.png\"\n",
    "                filepath = os.path.join(output_dir, filename)\n",
    "                cv2.imwrite(filepath, face_img)\n",
    "                print(f\"ğŸ“¸ ÄÃ£ lÆ°u khuÃ´n máº·t thá»© {count + 1}/{num_images}: {filepath}\")\n",
    "                count += 1\n",
    "\n",
    "                # Hiá»ƒn thá»‹ khung hÃ¬nh Ä‘áº§y Ä‘á»§ vá»›i khung Ä‘á»ƒ ngÆ°á»i dÃ¹ng theo dÃµi\n",
    "                frame_with_boxes = frame.copy()\n",
    "                for (t, r, b, l) in face_locations:\n",
    "                    t = max(0, t - padding)\n",
    "                    l = max(0, l - padding)\n",
    "                    r = min(frame.shape[1], r + padding)\n",
    "                    b = min(frame.shape[0], b + padding)\n",
    "                    cv2.rectangle(frame_with_boxes, (l, t), (r, b), (0, 255, 0), 2)\n",
    "                    cv2.putText(frame_with_boxes, \"Face\", (l, t - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                cv2.imshow(\"Face Detection\", frame_with_boxes)\n",
    "            else:\n",
    "                print(f\"âš ï¸ KhÃ´ng phÃ¡t hiá»‡n khuÃ´n máº·t trong khung hÃ¬nh thá»© {count + 1}\")\n",
    "                cv2.imshow(\"Face Detection\", frame)\n",
    "\n",
    "            # Nháº¥n 'q' Ä‘á»ƒ thoÃ¡t sá»›m\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                print(\"ğŸ›‘ NgÆ°á»i dÃ¹ng Ä‘Ã£ thoÃ¡t\")\n",
    "                break\n",
    "\n",
    "            # Äá»£i 1 giÃ¢y giá»¯a cÃ¡c áº£nh\n",
    "            time.sleep(1)\n",
    "\n",
    "        # Giáº£i phÃ³ng webcam vÃ  Ä‘Ã³ng cá»­a sá»•\n",
    "        video.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(f\"âœ… HoÃ n táº¥t! ÄÃ£ lÆ°u {count} áº£nh khuÃ´n máº·t vÃ o {output_dir}\")\n",
    "\n",
    "# Sá»­ dá»¥ng\n",
    "if __name__ == \"__main__\":\n",
    "    # Khá»Ÿi táº¡o há»‡ thá»‘ng vá»›i thÆ° má»¥c lÆ°u trá»¯ dataset\n",
    "    frs = FaceRecognitionSystem(dataset_path=\"dataset\")\n",
    "    \n",
    "    # Chá»¥p 10 áº£nh khuÃ´n máº·t, lÆ°u vá»›i tÃªn ngÆ°á»i (hoáº·c dÃ¹ng timestamp náº¿u khÃ´ng cung cáº¥p tÃªn)\n",
    "    person_name = input(\"Nháº­p tÃªn ngÆ°á»i (hoáº·c Ä‘á»ƒ trá»‘ng Ä‘á»ƒ dÃ¹ng timestamp): \").strip()\n",
    "    frs.capture_images(num_images=10, person_name=person_name if person_name else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a93f302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import face_recognition\n",
    "\n",
    "class FaceExtractor:\n",
    "    def __init__(self, dataset_path=r\"C:\\Users\\Divu\\Desktop\\DADN\\detect_face\\dataset\", output_dir=\"extracted_faces\"):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.output_dir = output_dir\n",
    "        self.detection_method = \"hog\"  # CÃ³ thá»ƒ Ä‘á»•i thÃ nh \"cnn\" náº¿u dÃ¹ng GPU\n",
    "\n",
    "    def draw_rectangles(self, face_img):\n",
    "        \"\"\"Váº½ khung hÃ¬nh chá»¯ nháº­t quanh khuÃ´n máº·t trÃªn vÃ¹ng Ä‘Ã£ cáº¯t.\"\"\"\n",
    "        padding = 20  # Sá»‘ pixel má»Ÿ rá»™ng má»—i cáº¡nh\n",
    "        top_padded = padding\n",
    "        right_padded = face_img.shape[1] - padding\n",
    "        bottom_padded = face_img.shape[0] - padding\n",
    "        left_padded = padding\n",
    "        cv2.rectangle(face_img, (left_padded, top_padded), (right_padded, bottom_padded), (0, 255, 0), 2)\n",
    "        cv2.putText(face_img, \"Face\", (left_padded, top_padded - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        return face_img\n",
    "\n",
    "    def extract_faces(self):\n",
    "        \"\"\"Cáº¯t khuÃ´n máº·t tá»« áº£nh trong dataset vÃ  lÆ°u theo cáº¥u trÃºc, giá»¯ cáº¥u trÃºc thÆ° má»¥c.\"\"\"\n",
    "        print(f\"ğŸš€ Báº¯t Ä‘áº§u trÃ­ch xuáº¥t khuÃ´n máº·t tá»« dataset: {self.dataset_path}\")\n",
    "        \n",
    "        # Táº¡o thÆ° má»¥c Ä‘áº§u ra náº¿u chÆ°a tá»“n táº¡i\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "\n",
    "        # Láº¥y danh sÃ¡ch cÃ¡c thÆ° má»¥c con (má»—i thÆ° má»¥c lÃ  má»™t ngÆ°á»i/nhÃ£n)\n",
    "        subdirs = [d for d in os.listdir(self.dataset_path) \n",
    "                  if os.path.isdir(os.path.join(self.dataset_path, d))]\n",
    "        \n",
    "        if not subdirs:\n",
    "            print(\"âŒ KhÃ´ng tÃ¬m tháº¥y thÆ° má»¥c con nÃ o trong dataset\")\n",
    "            return\n",
    "\n",
    "        total_face_count = 0\n",
    "        image_extensions = (\".jpg\", \".jpeg\", \".png\")\n",
    "\n",
    "        for subdir in subdirs:\n",
    "            input_subdir = os.path.join(self.dataset_path, subdir)\n",
    "            output_subdir = os.path.join(self.output_dir, subdir)\n",
    "            os.makedirs(output_subdir, exist_ok=True)\n",
    "            \n",
    "            print(f\"ğŸ“‚ Xá»­ lÃ½ thÆ° má»¥c: {subdir}\")\n",
    "            \n",
    "            # Láº¥y danh sÃ¡ch áº£nh trong thÆ° má»¥c con\n",
    "            image_paths = [os.path.join(input_subdir, f) for f in os.listdir(input_subdir) \n",
    "                          if f.lower().endswith(image_extensions)]\n",
    "            \n",
    "            face_count = 0\n",
    "            for idx, image_path in enumerate(image_paths):\n",
    "                print(f\"ğŸ“¸ Xá»­ lÃ½ áº£nh {idx + 1}/{len(image_paths)}: {image_path}\")\n",
    "                \n",
    "                image = cv2.imread(image_path)\n",
    "                if image is None:\n",
    "                    print(f\"âš ï¸ KhÃ´ng thá»ƒ Ä‘á»c áº£nh: {image_path}\")\n",
    "                    continue\n",
    "\n",
    "                rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                face_locations = face_recognition.face_locations(rgb_image, model=self.detection_method)\n",
    "\n",
    "                if not face_locations:\n",
    "                    print(f\"âš ï¸ KhÃ´ng phÃ¡t hiá»‡n khuÃ´n máº·t trong: {image_path}\")\n",
    "                    continue\n",
    "\n",
    "                for face_idx, (top, right, bottom, left) in enumerate(face_locations):\n",
    "                    padding = 30\n",
    "                    top = max(0, top - padding)\n",
    "                    left = max(0, left - padding)\n",
    "                    right = min(image.shape[1], right + padding)\n",
    "                    bottom = min(image.shape[0], bottom + padding)\n",
    "\n",
    "                    face_img = image[top:bottom, left:right]\n",
    "                    \n",
    "                    if face_img.size == 0:\n",
    "                        print(f\"âš ï¸ VÃ¹ng khuÃ´n máº·t khÃ´ng há»£p lá»‡ trong: {image_path}\")\n",
    "                        continue\n",
    "\n",
    "                    filename = f\"face_{idx:05d}_{face_idx}.png\"\n",
    "                    filepath = os.path.join(output_subdir, filename)\n",
    "                    cv2.imwrite(filepath, face_img)\n",
    "                    print(f\"âœ… ÄÃ£ lÆ°u khuÃ´n máº·t: {filepath}\")\n",
    "                    face_count += 1\n",
    "\n",
    "            print(f\"âœ… HoÃ n táº¥t thÆ° má»¥c {subdir}: {face_count} khuÃ´n máº·t\")\n",
    "            total_face_count += face_count\n",
    "\n",
    "        print(f\"âœ… HoÃ n táº¥t toÃ n bá»™ dataset! ÄÃ£ lÆ°u {total_face_count} khuÃ´n máº·t vÃ o {self.output_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Nháº­p Ä‘Æ°á»ng dáº«n Ä‘áº¿n dataset\n",
    "\n",
    "    extractor = FaceExtractor( )\n",
    "    extractor.extract_faces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4828ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Number of classes: 3\n",
      "Labels: {'temp_20250410_140340': 0, 'temp_20250413_215507': 1, 'temp_20250417_160515': 2}\n",
      "Training model...\n",
      "Epoch 1/10, Loss: 1.1051, Accuracy: 27.59%\n",
      "Epoch 2/10, Loss: 1.0514, Accuracy: 55.17%\n",
      "Epoch 3/10, Loss: 0.9945, Accuracy: 55.17%\n",
      "Epoch 4/10, Loss: 0.8806, Accuracy: 65.52%\n",
      "Epoch 5/10, Loss: 0.8080, Accuracy: 62.07%\n",
      "Epoch 6/10, Loss: 0.6457, Accuracy: 82.76%\n",
      "Epoch 7/10, Loss: 0.4848, Accuracy: 93.10%\n",
      "Epoch 8/10, Loss: 0.3638, Accuracy: 100.00%\n",
      "Epoch 9/10, Loss: 0.2150, Accuracy: 100.00%\n",
      "Epoch 10/10, Loss: 0.1548, Accuracy: 100.00%\n",
      "Model saved to face_recognition_model.pth\n",
      "\n",
      "Testing prediction time...\n",
      "Prediction result: temp_20250413_215507 (Prob: 0.9172)\n",
      "Inference time: 0.010005 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "# Äá»‹nh nghÄ©a dataset tá»« thÆ° má»¥c\n",
    "class FaceRecognitionDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.label_to_idx = {}\n",
    "        \n",
    "        # Láº¥y danh sÃ¡ch cÃ¡c folder (nhÃ£n), bá» qua folder \"unknown\"\n",
    "        folders = [f for f in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, f)) and f.lower() != \"unknown\"]\n",
    "        for idx, folder in enumerate(sorted(folders)):\n",
    "            self.label_to_idx[folder] = idx\n",
    "            # Láº¥y táº¥t cáº£ file áº£nh trong folder\n",
    "            image_files = glob.glob(os.path.join(root_dir, folder, \"*.jpg\")) + \\\n",
    "                         glob.glob(os.path.join(root_dir, folder, \"*.png\"))\n",
    "            for img_path in image_files:\n",
    "                self.image_paths.append(img_path)\n",
    "                self.labels.append(idx)\n",
    "        \n",
    "        self.num_classes = len(self.label_to_idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "# Äá»‹nh nghÄ©a mÃ´ hÃ¬nh CNN cho nháº­n diá»‡n khuÃ´n máº·t\n",
    "class FaceRecognitionCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(FaceRecognitionCNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),  # Input: 64x64x3\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # 32x32x16\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # 16x16x32\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)   # 8x8x64\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(8 * 8 * 64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "# HÃ m huáº¥n luyá»‡n mÃ´ hÃ¬nh\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs=5, device='cuda'):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(dataloader):.4f}, Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "# HÃ m dá»± Ä‘oÃ¡n vÃ  kiá»ƒm tra thá»i gian\n",
    "def predict(model, image, transform, label_to_idx, device='cuda', threshold=0.7):\n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        image = transform(image).unsqueeze(0).to(device)\n",
    "        output = model(image)\n",
    "        probabilities = torch.softmax(output, dim=1)\n",
    "        max_prob, predicted = torch.max(probabilities, 1)\n",
    "        # Kiá»ƒm tra ngÆ°á»¡ng Ä‘á»ƒ xÃ¡c Ä‘á»‹nh unknown\n",
    "        if max_prob.item() < threshold:\n",
    "            result = \"Unknown\"\n",
    "        else:\n",
    "            # Láº¥y tÃªn nhÃ£n tá»« chá»‰ sá»‘\n",
    "            idx_to_label = {v: k for k, v in label_to_idx.items()}\n",
    "            result = f\"{idx_to_label[predicted.item()]} (Prob: {max_prob.item():.4f})\"\n",
    "    end_time = time.time()\n",
    "    inference_time = end_time - start_time\n",
    "    return result, inference_time\n",
    "\n",
    "# Main\n",
    "if __name__ == \"__main__\":\n",
    "    # Thiáº¿t láº­p thiáº¿t bá»‹\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Using device: {device}')\n",
    "\n",
    "    # ÄÆ°á»ng dáº«n Ä‘áº¿n thÆ° má»¥c chá»©a dá»¯ liá»‡u\n",
    "    data_dir =r\"C:\\Users\\Divu\\Desktop\\DADN\\extracted_faces\"  # Thay báº±ng Ä‘Æ°á»ng dáº«n thá»±c táº¿, vÃ­ dá»¥: \"D:/faces_dataset\"\n",
    "\n",
    "    # Transform cho áº£nh\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((64, 64)),  # Resize vá» 64x64 Ä‘á»ƒ giáº£m tÃ­nh toÃ¡n\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    # Táº¡o dataset vÃ  dataloader\n",
    "    dataset = FaceRecognitionDataset(root_dir=data_dir, transform=transform)\n",
    "    if len(dataset) == 0:\n",
    "        print(\"No valid images found in the dataset. Please check the directory structure.\")\n",
    "        exit()\n",
    "    \n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    num_classes = dataset.num_classes\n",
    "    label_to_idx = dataset.label_to_idx\n",
    "    print(f\"Number of classes: {num_classes}\")\n",
    "    print(f\"Labels: {label_to_idx}\")\n",
    "\n",
    "    # Khá»Ÿi táº¡o mÃ´ hÃ¬nh, loss, optimizer\n",
    "    model = FaceRecognitionCNN(num_classes=num_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Huáº¥n luyá»‡n mÃ´ hÃ¬nh\n",
    "    print(\"Training model...\")\n",
    "    train_model(model, dataloader, criterion, optimizer, num_epochs=10, device=device)\n",
    "\n",
    "    # LÆ°u mÃ´ hÃ¬nh\n",
    "    model_path = \"face_recognition_model.pth\"\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "\n",
    "    # Äo thá»i gian dá»± Ä‘oÃ¡n\n",
    "    print(\"\\nTesting prediction time...\")\n",
    "    # Sá»­ dá»¥ng má»™t áº£nh thá»±c táº¿ Ä‘á»ƒ dá»± Ä‘oÃ¡n (thay báº±ng Ä‘Æ°á»ng dáº«n áº£nh cá»§a báº¡n)\n",
    "    test_image_path = r\"../extracted_faces/temp_20250413_215507/face_00002_0.png\"  # Thay báº±ng Ä‘Æ°á»ng dáº«n áº£nh thá»±c táº¿\n",
    "    try:\n",
    "        test_image = Image.open(test_image_path).convert('RGB')\n",
    "        result, inference_time = predict(model, test_image, transform, label_to_idx, device, threshold=0.7)\n",
    "        print(f\"Prediction result: {result}\")\n",
    "        print(f\"Inference time: {inference_time:.6f} seconds\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Test image not found. Please provide a valid image path.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0aab0b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Number of classes: 3\n",
      "Labels: {'temp_20250410_140340': 0, 'temp_20250413_215507': 1, 'temp_20250417_160515': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Divu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Divu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Epoch 1/10, Loss: 1.1912, Accuracy: 34.48%\n",
      "Epoch 2/10, Loss: 0.0081, Accuracy: 100.00%\n",
      "Epoch 3/10, Loss: 0.0015, Accuracy: 100.00%\n",
      "Epoch 4/10, Loss: 0.0007, Accuracy: 100.00%\n",
      "Epoch 5/10, Loss: 0.0004, Accuracy: 100.00%\n",
      "Epoch 6/10, Loss: 0.0003, Accuracy: 100.00%\n",
      "Epoch 7/10, Loss: 0.0002, Accuracy: 100.00%\n",
      "Epoch 8/10, Loss: 0.0002, Accuracy: 100.00%\n",
      "Epoch 9/10, Loss: 0.0001, Accuracy: 100.00%\n",
      "Epoch 10/10, Loss: 0.0001, Accuracy: 100.00%\n",
      "Model saved to face_recognition_resnet18.pth\n",
      "\n",
      "Testing prediction time...\n",
      "Prediction result: temp_20250413_215507 (Prob: 1.0000)\n",
      "Inference time: 0.020677 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "# Äá»‹nh nghÄ©a dataset tá»« thÆ° má»¥c\n",
    "class FaceRecognitionDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.label_to_idx = {}\n",
    "        \n",
    "        # Láº¥y danh sÃ¡ch cÃ¡c folder (nhÃ£n), bá» qua folder \"unknown\"\n",
    "        folders = [f for f in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, f)) and f.lower() != \"unknown\"]\n",
    "        for idx, folder in enumerate(sorted(folders)):\n",
    "            self.label_to_idx[folder] = idx\n",
    "            # Láº¥y táº¥t cáº£ file áº£nh trong folder\n",
    "            image_files = glob.glob(os.path.join(root_dir, folder, \"*.jpg\")) + \\\n",
    "                         glob.glob(os.path.join(root_dir, folder, \"*.png\"))\n",
    "            for img_path in image_files:\n",
    "                self.image_paths.append(img_path)\n",
    "                self.labels.append(idx)\n",
    "        \n",
    "        self.num_classes = len(self.label_to_idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "# Äá»‹nh nghÄ©a mÃ´ hÃ¬nh ResNet18 cho nháº­n diá»‡n khuÃ´n máº·t\n",
    "class FaceRecognitionResNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(FaceRecognitionResNet, self).__init__()\n",
    "        # Táº£i mÃ´ hÃ¬nh ResNet18 pre-trained\n",
    "        self.resnet = models.resnet18(pretrained=True)\n",
    "        # Thay táº§ng fully connected cuá»‘i cÃ¹ng\n",
    "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "# HÃ m huáº¥n luyá»‡n mÃ´ hÃ¬nh\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs=10, device='cuda'):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(dataloader):.4f}, Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "# HÃ m dá»± Ä‘oÃ¡n vÃ  kiá»ƒm tra thá»i gian\n",
    "def predict(model, image, transform, label_to_idx, device='cuda', threshold=0.7):\n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        image = transform(image).unsqueeze(0).to(device)\n",
    "        output = model(image)\n",
    "        probabilities = torch.softmax(output, dim=1)\n",
    "        max_prob, predicted = torch.max(probabilities, 1)\n",
    "        # Kiá»ƒm tra ngÆ°á»¡ng Ä‘á»ƒ xÃ¡c Ä‘á»‹nh unknown\n",
    "        if max_prob.item() < threshold:\n",
    "            result = \"Unknown\"\n",
    "        else:\n",
    "            # Láº¥y tÃªn nhÃ£n tá»« chá»‰ sá»‘\n",
    "            idx_to_label = {v: k for k, v in label_to_idx.items()}\n",
    "            result = f\"{idx_to_label[predicted.item()]} (Prob: {max_prob.item():.4f})\"\n",
    "    end_time = time.time()\n",
    "    inference_time = end_time - start_time\n",
    "    return result, inference_time\n",
    "\n",
    "# Main\n",
    "if __name__ == \"__main__\":\n",
    "    # Thiáº¿t láº­p thiáº¿t bá»‹\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Using device: {device}')\n",
    "\n",
    "    # ÄÆ°á»ng dáº«n Ä‘áº¿n thÆ° má»¥c chá»©a dá»¯ liá»‡u\n",
    "    data_dir = r\"C:\\Users\\Divu\\Desktop\\DADN\\extracted_faces\"   # Thay báº±ng Ä‘Æ°á»ng dáº«n thá»±c táº¿, vÃ­ dá»¥: \"D:/faces_dataset\"\n",
    "\n",
    "    # Transform cho áº£nh (phÃ¹ há»£p vá»›i ResNet)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # ResNet yÃªu cáº§u kÃ­ch thÆ°á»›c 224x224\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Chuáº©n hÃ³a theo ImageNet\n",
    "    ])\n",
    "\n",
    "    # Táº¡o dataset vÃ  dataloader\n",
    "    dataset = FaceRecognitionDataset(root_dir=data_dir, transform=transform)\n",
    "    if len(dataset) == 0:\n",
    "        print(\"No valid images found in the dataset. Please check the directory structure.\")\n",
    "        exit()\n",
    "    \n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    num_classes = dataset.num_classes\n",
    "    label_to_idx = dataset.label_to_idx\n",
    "    print(f\"Number of classes: {num_classes}\")\n",
    "    print(f\"Labels: {label_to_idx}\")\n",
    "\n",
    "    # Khá»Ÿi táº¡o mÃ´ hÃ¬nh, loss, optimizer\n",
    "    model = FaceRecognitionResNet(num_classes=num_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Huáº¥n luyá»‡n mÃ´ hÃ¬nh\n",
    "    print(\"Training model...\")\n",
    "    train_model(model, dataloader, criterion, optimizer, num_epochs=10, device=device)\n",
    "\n",
    "    # LÆ°u mÃ´ hÃ¬nh\n",
    "    model_path = \"face_recognition_resnet18.pth\"\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "\n",
    "    # Äo thá»i gian dá»± Ä‘oÃ¡n\n",
    "    print(\"\\nTesting prediction time...\")\n",
    "    # Sá»­ dá»¥ng má»™t áº£nh thá»±c táº¿ Ä‘á»ƒ dá»± Ä‘oÃ¡n (thay báº±ng Ä‘Æ°á»ng dáº«n áº£nh cá»§a báº¡n)\n",
    "    test_image_path =  r\"../extracted_faces/temp_20250413_215507/face_00002_0.png\"  # Thay báº±ng Ä‘Æ°á»ng dáº«n áº£nh thá»±c táº¿\n",
    "    try:\n",
    "        test_image = Image.open(test_image_path).convert('RGB')\n",
    "        result, inference_time = predict(model, test_image, transform, label_to_idx, device, threshold=0.7)\n",
    "        print(f\"Prediction result: {result}\")\n",
    "        print(f\"Inference time: {inference_time:.6f} seconds\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Test image not found. Please provide a valid image path.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
